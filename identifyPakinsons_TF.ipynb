{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Identifying Parkinson's disease with Keras #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximately one million people have Parkinson’s disease in the U.S. and there are around 50,000 new cases diagnosed each year where most patients are middel-aged. Eventhough there are medications that can help patients with the symptom, there is no cure for Parkinson’s disease. \n",
    "\n",
    "In this project a model that identifies if a person has pakinson's disease or not using the Keras API in Tensorflow 2.0. In such deep learning framework multiple layers of neurons are built to identify the status of the patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Parkinsons_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1cd6c9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.countplot(df['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('status', axis=1).values\n",
    "y = df['status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 22)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(22, activation='relu'))\n",
    "\n",
    "model.add(Dense(11, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156 samples, validate on 39 samples\n",
      "Epoch 1/400\n",
      "156/156 [==============================] - 2s 11ms/sample - loss: 0.7489 - val_loss: 0.7433\n",
      "Epoch 2/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.7244 - val_loss: 0.7235\n",
      "Epoch 3/400\n",
      "156/156 [==============================] - 0s 624us/sample - loss: 0.6999 - val_loss: 0.7042\n",
      "Epoch 4/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.6792 - val_loss: 0.6862\n",
      "Epoch 5/400\n",
      "156/156 [==============================] - 0s 601us/sample - loss: 0.6594 - val_loss: 0.6694\n",
      "Epoch 6/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.6395 - val_loss: 0.6500\n",
      "Epoch 7/400\n",
      "156/156 [==============================] - 0s 614us/sample - loss: 0.6193 - val_loss: 0.6291\n",
      "Epoch 8/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.5978 - val_loss: 0.6081\n",
      "Epoch 9/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.5778 - val_loss: 0.5887\n",
      "Epoch 10/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.5593 - val_loss: 0.5688\n",
      "Epoch 11/400\n",
      "156/156 [==============================] - 0s 648us/sample - loss: 0.5406 - val_loss: 0.5507\n",
      "Epoch 12/400\n",
      "156/156 [==============================] - 0s 610us/sample - loss: 0.5256 - val_loss: 0.5340\n",
      "Epoch 13/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.5107 - val_loss: 0.5189\n",
      "Epoch 14/400\n",
      "156/156 [==============================] - 0s 693us/sample - loss: 0.4982 - val_loss: 0.5052\n",
      "Epoch 15/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.4865 - val_loss: 0.4924\n",
      "Epoch 16/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.4766 - val_loss: 0.4811\n",
      "Epoch 17/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.4672 - val_loss: 0.4705\n",
      "Epoch 18/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.4594 - val_loss: 0.4600\n",
      "Epoch 19/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.4512 - val_loss: 0.4495\n",
      "Epoch 20/400\n",
      "156/156 [==============================] - 0s 656us/sample - loss: 0.4434 - val_loss: 0.4389\n",
      "Epoch 21/400\n",
      "156/156 [==============================] - 0s 634us/sample - loss: 0.4362 - val_loss: 0.4282\n",
      "Epoch 22/400\n",
      "156/156 [==============================] - 0s 644us/sample - loss: 0.4287 - val_loss: 0.4187\n",
      "Epoch 23/400\n",
      "156/156 [==============================] - 0s 613us/sample - loss: 0.4230 - val_loss: 0.4102\n",
      "Epoch 24/400\n",
      "156/156 [==============================] - 0s 608us/sample - loss: 0.4162 - val_loss: 0.4027\n",
      "Epoch 25/400\n",
      "156/156 [==============================] - 0s 626us/sample - loss: 0.4106 - val_loss: 0.3954\n",
      "Epoch 26/400\n",
      "156/156 [==============================] - 0s 644us/sample - loss: 0.4056 - val_loss: 0.3888\n",
      "Epoch 27/400\n",
      "156/156 [==============================] - 0s 674us/sample - loss: 0.4010 - val_loss: 0.3825\n",
      "Epoch 28/400\n",
      "156/156 [==============================] - 0s 774us/sample - loss: 0.3968 - val_loss: 0.3767\n",
      "Epoch 29/400\n",
      "156/156 [==============================] - 0s 817us/sample - loss: 0.3928 - val_loss: 0.3710\n",
      "Epoch 30/400\n",
      "156/156 [==============================] - 0s 741us/sample - loss: 0.3898 - val_loss: 0.3659\n",
      "Epoch 31/400\n",
      "156/156 [==============================] - 0s 691us/sample - loss: 0.3858 - val_loss: 0.3614\n",
      "Epoch 32/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.3834 - val_loss: 0.3570\n",
      "Epoch 33/400\n",
      "156/156 [==============================] - 0s 659us/sample - loss: 0.3802 - val_loss: 0.3531\n",
      "Epoch 34/400\n",
      "156/156 [==============================] - 0s 755us/sample - loss: 0.3774 - val_loss: 0.3495\n",
      "Epoch 35/400\n",
      "156/156 [==============================] - 0s 661us/sample - loss: 0.3744 - val_loss: 0.3458\n",
      "Epoch 36/400\n",
      "156/156 [==============================] - 0s 661us/sample - loss: 0.3722 - val_loss: 0.3425\n",
      "Epoch 37/400\n",
      "156/156 [==============================] - 0s 785us/sample - loss: 0.3701 - val_loss: 0.3395\n",
      "Epoch 38/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.3682 - val_loss: 0.3376\n",
      "Epoch 39/400\n",
      "156/156 [==============================] - 0s 633us/sample - loss: 0.3656 - val_loss: 0.3349\n",
      "Epoch 40/400\n",
      "156/156 [==============================] - 0s 764us/sample - loss: 0.3637 - val_loss: 0.3322\n",
      "Epoch 41/400\n",
      "156/156 [==============================] - 0s 785us/sample - loss: 0.3614 - val_loss: 0.3301\n",
      "Epoch 42/400\n",
      "156/156 [==============================] - 0s 774us/sample - loss: 0.3602 - val_loss: 0.3291\n",
      "Epoch 43/400\n",
      "156/156 [==============================] - 0s 789us/sample - loss: 0.3577 - val_loss: 0.3267\n",
      "Epoch 44/400\n",
      "156/156 [==============================] - 0s 732us/sample - loss: 0.3557 - val_loss: 0.3246\n",
      "Epoch 45/400\n",
      "156/156 [==============================] - 0s 613us/sample - loss: 0.3546 - val_loss: 0.3220\n",
      "Epoch 46/400\n",
      "156/156 [==============================] - 0s 669us/sample - loss: 0.3530 - val_loss: 0.3203\n",
      "Epoch 47/400\n",
      "156/156 [==============================] - 0s 670us/sample - loss: 0.3512 - val_loss: 0.3199\n",
      "Epoch 48/400\n",
      "156/156 [==============================] - 0s 924us/sample - loss: 0.3490 - val_loss: 0.3184\n",
      "Epoch 49/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.3478 - val_loss: 0.3175\n",
      "Epoch 50/400\n",
      "156/156 [==============================] - 0s 624us/sample - loss: 0.3458 - val_loss: 0.3154\n",
      "Epoch 51/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.3443 - val_loss: 0.3137\n",
      "Epoch 52/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.3427 - val_loss: 0.3120\n",
      "Epoch 53/400\n",
      "156/156 [==============================] - 0s 777us/sample - loss: 0.3412 - val_loss: 0.3112\n",
      "Epoch 54/400\n",
      "156/156 [==============================] - 0s 597us/sample - loss: 0.3394 - val_loss: 0.3098\n",
      "Epoch 55/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.3381 - val_loss: 0.3084\n",
      "Epoch 56/400\n",
      "156/156 [==============================] - 0s 604us/sample - loss: 0.3370 - val_loss: 0.3082\n",
      "Epoch 57/400\n",
      "156/156 [==============================] - 0s 618us/sample - loss: 0.3350 - val_loss: 0.3066\n",
      "Epoch 58/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.3359 - val_loss: 0.3075\n",
      "Epoch 59/400\n",
      "156/156 [==============================] - 0s 612us/sample - loss: 0.3330 - val_loss: 0.3039\n",
      "Epoch 60/400\n",
      "156/156 [==============================] - 0s 603us/sample - loss: 0.3307 - val_loss: 0.3025\n",
      "Epoch 61/400\n",
      "156/156 [==============================] - 0s 612us/sample - loss: 0.3294 - val_loss: 0.3015\n",
      "Epoch 62/400\n",
      "156/156 [==============================] - 0s 590us/sample - loss: 0.3291 - val_loss: 0.3027\n",
      "Epoch 63/400\n",
      "156/156 [==============================] - 0s 661us/sample - loss: 0.3263 - val_loss: 0.3018\n",
      "Epoch 64/400\n",
      "156/156 [==============================] - 0s 772us/sample - loss: 0.3249 - val_loss: 0.3011\n",
      "Epoch 65/400\n",
      "156/156 [==============================] - 0s 797us/sample - loss: 0.3234 - val_loss: 0.2999\n",
      "Epoch 66/400\n",
      "156/156 [==============================] - 0s 713us/sample - loss: 0.3224 - val_loss: 0.2985\n",
      "Epoch 67/400\n",
      "156/156 [==============================] - 0s 618us/sample - loss: 0.3208 - val_loss: 0.2965\n",
      "Epoch 68/400\n",
      "156/156 [==============================] - 0s 651us/sample - loss: 0.3197 - val_loss: 0.2960\n",
      "Epoch 69/400\n",
      "156/156 [==============================] - 0s 721us/sample - loss: 0.3186 - val_loss: 0.2951\n",
      "Epoch 70/400\n",
      "156/156 [==============================] - 0s 978us/sample - loss: 0.3179 - val_loss: 0.2971\n",
      "Epoch 71/400\n",
      "156/156 [==============================] - 0s 959us/sample - loss: 0.3153 - val_loss: 0.2962\n",
      "Epoch 72/400\n",
      "156/156 [==============================] - 0s 946us/sample - loss: 0.3138 - val_loss: 0.2945\n",
      "Epoch 73/400\n",
      "156/156 [==============================] - 0s 867us/sample - loss: 0.3131 - val_loss: 0.2949\n",
      "Epoch 74/400\n",
      "156/156 [==============================] - 0s 662us/sample - loss: 0.3108 - val_loss: 0.2936\n",
      "Epoch 75/400\n",
      "156/156 [==============================] - 0s 621us/sample - loss: 0.3100 - val_loss: 0.2907\n",
      "Epoch 76/400\n",
      "156/156 [==============================] - 0s 646us/sample - loss: 0.3087 - val_loss: 0.2899\n",
      "Epoch 77/400\n",
      "156/156 [==============================] - 0s 613us/sample - loss: 0.3075 - val_loss: 0.2928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/400\n",
      "156/156 [==============================] - 0s 695us/sample - loss: 0.3057 - val_loss: 0.2917\n",
      "Epoch 79/400\n",
      "156/156 [==============================] - 0s 718us/sample - loss: 0.3054 - val_loss: 0.2937\n",
      "Epoch 80/400\n",
      "156/156 [==============================] - 0s 728us/sample - loss: 0.3032 - val_loss: 0.2917\n",
      "Epoch 81/400\n",
      "156/156 [==============================] - 0s 693us/sample - loss: 0.3020 - val_loss: 0.2912\n",
      "Epoch 82/400\n",
      "156/156 [==============================] - 0s 620us/sample - loss: 0.3005 - val_loss: 0.2905\n",
      "Epoch 83/400\n",
      "156/156 [==============================] - 0s 644us/sample - loss: 0.2990 - val_loss: 0.2885\n",
      "Epoch 84/400\n",
      "156/156 [==============================] - 0s 620us/sample - loss: 0.2978 - val_loss: 0.2874\n",
      "Epoch 85/400\n",
      "156/156 [==============================] - 0s 615us/sample - loss: 0.2968 - val_loss: 0.2876\n",
      "Epoch 86/400\n",
      "156/156 [==============================] - 0s 606us/sample - loss: 0.2959 - val_loss: 0.2883\n",
      "Epoch 87/400\n",
      "156/156 [==============================] - 0s 579us/sample - loss: 0.2945 - val_loss: 0.2873\n",
      "Epoch 88/400\n",
      "156/156 [==============================] - 0s 616us/sample - loss: 0.2931 - val_loss: 0.2891\n",
      "Epoch 89/400\n",
      "156/156 [==============================] - 0s 603us/sample - loss: 0.2918 - val_loss: 0.2884\n",
      "Epoch 90/400\n",
      "156/156 [==============================] - 0s 612us/sample - loss: 0.2913 - val_loss: 0.2898\n",
      "Epoch 91/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.2898 - val_loss: 0.2880\n",
      "Epoch 92/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.2883 - val_loss: 0.2850\n",
      "Epoch 93/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2887 - val_loss: 0.2831\n",
      "Epoch 94/400\n",
      "156/156 [==============================] - 0s 603us/sample - loss: 0.2857 - val_loss: 0.2858\n",
      "Epoch 95/400\n",
      "156/156 [==============================] - 0s 664us/sample - loss: 0.2850 - val_loss: 0.2905\n",
      "Epoch 96/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.2842 - val_loss: 0.2914\n",
      "Epoch 97/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.2826 - val_loss: 0.2890\n",
      "Epoch 98/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.2860 - val_loss: 0.2805\n",
      "Epoch 99/400\n",
      "156/156 [==============================] - 0s 635us/sample - loss: 0.2808 - val_loss: 0.2842\n",
      "Epoch 100/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2784 - val_loss: 0.2846\n",
      "Epoch 101/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.2784 - val_loss: 0.2886\n",
      "Epoch 102/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2764 - val_loss: 0.2857\n",
      "Epoch 103/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.2759 - val_loss: 0.2822\n",
      "Epoch 104/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.2742 - val_loss: 0.2846\n",
      "Epoch 105/400\n",
      "156/156 [==============================] - 0s 646us/sample - loss: 0.2727 - val_loss: 0.2847\n",
      "Epoch 106/400\n",
      "156/156 [==============================] - 0s 671us/sample - loss: 0.2719 - val_loss: 0.2856\n",
      "Epoch 107/400\n",
      "156/156 [==============================] - 0s 617us/sample - loss: 0.2707 - val_loss: 0.2856\n",
      "Epoch 108/400\n",
      "156/156 [==============================] - 0s 640us/sample - loss: 0.2698 - val_loss: 0.2822\n",
      "Epoch 109/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.2687 - val_loss: 0.2809\n",
      "Epoch 110/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.2681 - val_loss: 0.2841\n",
      "Epoch 111/400\n",
      "156/156 [==============================] - 0s 660us/sample - loss: 0.2665 - val_loss: 0.2850\n",
      "Epoch 112/400\n",
      "156/156 [==============================] - 0s 656us/sample - loss: 0.2656 - val_loss: 0.2824\n",
      "Epoch 113/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.2656 - val_loss: 0.2802\n",
      "Epoch 114/400\n",
      "156/156 [==============================] - 0s 665us/sample - loss: 0.2633 - val_loss: 0.2837\n",
      "Epoch 115/400\n",
      "156/156 [==============================] - 0s 609us/sample - loss: 0.2621 - val_loss: 0.2856\n",
      "Epoch 116/400\n",
      "156/156 [==============================] - 0s 647us/sample - loss: 0.2616 - val_loss: 0.2847\n",
      "Epoch 117/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.2603 - val_loss: 0.2855\n",
      "Epoch 118/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.2596 - val_loss: 0.2865\n",
      "Epoch 119/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.2583 - val_loss: 0.2842\n",
      "Epoch 120/400\n",
      "156/156 [==============================] - 0s 706us/sample - loss: 0.2576 - val_loss: 0.2800\n",
      "Epoch 121/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.2564 - val_loss: 0.2798\n",
      "Epoch 122/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.2558 - val_loss: 0.2799\n",
      "Epoch 123/400\n",
      "156/156 [==============================] - 0s 966us/sample - loss: 0.2544 - val_loss: 0.2839\n",
      "Epoch 124/400\n",
      "156/156 [==============================] - 0s 947us/sample - loss: 0.2538 - val_loss: 0.2838\n",
      "Epoch 125/400\n",
      "156/156 [==============================] - 0s 689us/sample - loss: 0.2529 - val_loss: 0.2873\n",
      "Epoch 126/400\n",
      "156/156 [==============================] - 0s 643us/sample - loss: 0.2520 - val_loss: 0.2851\n",
      "Epoch 127/400\n",
      "156/156 [==============================] - 0s 911us/sample - loss: 0.2509 - val_loss: 0.2821\n",
      "Epoch 128/400\n",
      "156/156 [==============================] - 0s 684us/sample - loss: 0.2499 - val_loss: 0.2826\n",
      "Epoch 129/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.2489 - val_loss: 0.2805\n",
      "Epoch 130/400\n",
      "156/156 [==============================] - 0s 624us/sample - loss: 0.2489 - val_loss: 0.2778\n",
      "Epoch 131/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.2472 - val_loss: 0.2799\n",
      "Epoch 132/400\n",
      "156/156 [==============================] - 0s 829us/sample - loss: 0.2477 - val_loss: 0.2861\n",
      "Epoch 133/400\n",
      "156/156 [==============================] - 0s 735us/sample - loss: 0.2457 - val_loss: 0.2844\n",
      "Epoch 134/400\n",
      "156/156 [==============================] - 0s 774us/sample - loss: 0.2443 - val_loss: 0.2815\n",
      "Epoch 135/400\n",
      "156/156 [==============================] - 0s 655us/sample - loss: 0.2445 - val_loss: 0.2773\n",
      "Epoch 136/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2431 - val_loss: 0.2768\n",
      "Epoch 137/400\n",
      "156/156 [==============================] - 0s 665us/sample - loss: 0.2418 - val_loss: 0.2786\n",
      "Epoch 138/400\n",
      "156/156 [==============================] - 0s 674us/sample - loss: 0.2417 - val_loss: 0.2784\n",
      "Epoch 139/400\n",
      "156/156 [==============================] - 0s 663us/sample - loss: 0.2401 - val_loss: 0.2805\n",
      "Epoch 140/400\n",
      "156/156 [==============================] - 0s 756us/sample - loss: 0.2392 - val_loss: 0.2839\n",
      "Epoch 141/400\n",
      "156/156 [==============================] - 0s 641us/sample - loss: 0.2393 - val_loss: 0.2868\n",
      "Epoch 142/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.2384 - val_loss: 0.2859\n",
      "Epoch 143/400\n",
      "156/156 [==============================] - 0s 664us/sample - loss: 0.2370 - val_loss: 0.2761\n",
      "Epoch 144/400\n",
      "156/156 [==============================] - 0s 611us/sample - loss: 0.2371 - val_loss: 0.2718\n",
      "Epoch 145/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.2363 - val_loss: 0.2774\n",
      "Epoch 146/400\n",
      "156/156 [==============================] - 0s 663us/sample - loss: 0.2345 - val_loss: 0.2799\n",
      "Epoch 147/400\n",
      "156/156 [==============================] - 0s 641us/sample - loss: 0.2340 - val_loss: 0.2799\n",
      "Epoch 148/400\n",
      "156/156 [==============================] - 0s 748us/sample - loss: 0.2326 - val_loss: 0.2787\n",
      "Epoch 149/400\n",
      "156/156 [==============================] - 0s 821us/sample - loss: 0.2322 - val_loss: 0.2799\n",
      "Epoch 150/400\n",
      "156/156 [==============================] - 0s 740us/sample - loss: 0.2309 - val_loss: 0.2783\n",
      "Epoch 151/400\n",
      "156/156 [==============================] - 0s 694us/sample - loss: 0.2306 - val_loss: 0.2759\n",
      "Epoch 152/400\n",
      "156/156 [==============================] - 0s 694us/sample - loss: 0.2295 - val_loss: 0.2744\n",
      "Epoch 153/400\n",
      "156/156 [==============================] - 0s 659us/sample - loss: 0.2304 - val_loss: 0.2796\n",
      "Epoch 154/400\n",
      "156/156 [==============================] - 0s 685us/sample - loss: 0.2280 - val_loss: 0.2777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/400\n",
      "156/156 [==============================] - 0s 656us/sample - loss: 0.2279 - val_loss: 0.2734\n",
      "Epoch 156/400\n",
      "156/156 [==============================] - 0s 679us/sample - loss: 0.2272 - val_loss: 0.2780\n",
      "Epoch 157/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.2258 - val_loss: 0.2777\n",
      "Epoch 158/400\n",
      "156/156 [==============================] - 0s 671us/sample - loss: 0.2251 - val_loss: 0.2784\n",
      "Epoch 159/400\n",
      "156/156 [==============================] - 0s 582us/sample - loss: 0.2236 - val_loss: 0.2750\n",
      "Epoch 160/400\n",
      "156/156 [==============================] - 0s 619us/sample - loss: 0.2231 - val_loss: 0.2731\n",
      "Epoch 161/400\n",
      "156/156 [==============================] - 0s 614us/sample - loss: 0.2225 - val_loss: 0.2706\n",
      "Epoch 162/400\n",
      "156/156 [==============================] - 0s 607us/sample - loss: 0.2220 - val_loss: 0.2712\n",
      "Epoch 163/400\n",
      "156/156 [==============================] - 0s 575us/sample - loss: 0.2213 - val_loss: 0.2753\n",
      "Epoch 164/400\n",
      "156/156 [==============================] - 0s 606us/sample - loss: 0.2204 - val_loss: 0.2737\n",
      "Epoch 165/400\n",
      "156/156 [==============================] - 0s 597us/sample - loss: 0.2194 - val_loss: 0.2750\n",
      "Epoch 166/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.2184 - val_loss: 0.2759\n",
      "Epoch 167/400\n",
      "156/156 [==============================] - 0s 596us/sample - loss: 0.2183 - val_loss: 0.2762\n",
      "Epoch 168/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.2186 - val_loss: 0.2703\n",
      "Epoch 169/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.2163 - val_loss: 0.2727\n",
      "Epoch 170/400\n",
      "156/156 [==============================] - 0s 611us/sample - loss: 0.2157 - val_loss: 0.2760\n",
      "Epoch 171/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.2163 - val_loss: 0.2721\n",
      "Epoch 172/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.2143 - val_loss: 0.2753\n",
      "Epoch 173/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.2153 - val_loss: 0.2800\n",
      "Epoch 174/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.2126 - val_loss: 0.2740\n",
      "Epoch 175/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.2116 - val_loss: 0.2682\n",
      "Epoch 176/400\n",
      "156/156 [==============================] - 0s 669us/sample - loss: 0.2114 - val_loss: 0.2672\n",
      "Epoch 177/400\n",
      "156/156 [==============================] - 0s 620us/sample - loss: 0.2114 - val_loss: 0.2645\n",
      "Epoch 178/400\n",
      "156/156 [==============================] - 0s 606us/sample - loss: 0.2099 - val_loss: 0.2696\n",
      "Epoch 179/400\n",
      "156/156 [==============================] - 0s 605us/sample - loss: 0.2099 - val_loss: 0.2722\n",
      "Epoch 180/400\n",
      "156/156 [==============================] - 0s 645us/sample - loss: 0.2090 - val_loss: 0.2708\n",
      "Epoch 181/400\n",
      "156/156 [==============================] - 0s 657us/sample - loss: 0.2082 - val_loss: 0.2723\n",
      "Epoch 182/400\n",
      "156/156 [==============================] - 0s 767us/sample - loss: 0.2071 - val_loss: 0.2709\n",
      "Epoch 183/400\n",
      "156/156 [==============================] - 0s 596us/sample - loss: 0.2073 - val_loss: 0.2644\n",
      "Epoch 184/400\n",
      "156/156 [==============================] - 0s 643us/sample - loss: 0.2059 - val_loss: 0.2664\n",
      "Epoch 185/400\n",
      "156/156 [==============================] - 0s 622us/sample - loss: 0.2055 - val_loss: 0.2718\n",
      "Epoch 186/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.2046 - val_loss: 0.2714\n",
      "Epoch 187/400\n",
      "156/156 [==============================] - 0s 617us/sample - loss: 0.2039 - val_loss: 0.2670\n",
      "Epoch 188/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2029 - val_loss: 0.2653\n",
      "Epoch 189/400\n",
      "156/156 [==============================] - 0s 664us/sample - loss: 0.2021 - val_loss: 0.2669\n",
      "Epoch 190/400\n",
      "156/156 [==============================] - 0s 605us/sample - loss: 0.2017 - val_loss: 0.2677\n",
      "Epoch 191/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.2012 - val_loss: 0.2663\n",
      "Epoch 192/400\n",
      "156/156 [==============================] - 0s 597us/sample - loss: 0.2002 - val_loss: 0.2683\n",
      "Epoch 193/400\n",
      "156/156 [==============================] - 0s 632us/sample - loss: 0.1996 - val_loss: 0.2662\n",
      "Epoch 194/400\n",
      "156/156 [==============================] - 0s 635us/sample - loss: 0.1994 - val_loss: 0.2626\n",
      "Epoch 195/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.1979 - val_loss: 0.2656\n",
      "Epoch 196/400\n",
      "156/156 [==============================] - 0s 642us/sample - loss: 0.1973 - val_loss: 0.2676\n",
      "Epoch 197/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.1972 - val_loss: 0.2674\n",
      "Epoch 198/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.1964 - val_loss: 0.2655\n",
      "Epoch 199/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.1977 - val_loss: 0.2600\n",
      "Epoch 200/400\n",
      "156/156 [==============================] - 0s 644us/sample - loss: 0.1946 - val_loss: 0.2659\n",
      "Epoch 201/400\n",
      "156/156 [==============================] - 0s 648us/sample - loss: 0.1956 - val_loss: 0.2735\n",
      "Epoch 202/400\n",
      "156/156 [==============================] - ETA: 0s - loss: 0.229 - 0s 635us/sample - loss: 0.1941 - val_loss: 0.2647\n",
      "Epoch 203/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.1930 - val_loss: 0.2644\n",
      "Epoch 204/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.1926 - val_loss: 0.2631\n",
      "Epoch 205/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.1913 - val_loss: 0.2577\n",
      "Epoch 206/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.1918 - val_loss: 0.2541\n",
      "Epoch 207/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.1912 - val_loss: 0.2626\n",
      "Epoch 208/400\n",
      "156/156 [==============================] - 0s 613us/sample - loss: 0.1898 - val_loss: 0.2624\n",
      "Epoch 209/400\n",
      "156/156 [==============================] - 0s 651us/sample - loss: 0.1891 - val_loss: 0.2656\n",
      "Epoch 210/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.1889 - val_loss: 0.2655\n",
      "Epoch 211/400\n",
      "156/156 [==============================] - 0s 679us/sample - loss: 0.1890 - val_loss: 0.2553\n",
      "Epoch 212/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.1877 - val_loss: 0.2595\n",
      "Epoch 213/400\n",
      "156/156 [==============================] - 0s 602us/sample - loss: 0.1873 - val_loss: 0.2556\n",
      "Epoch 214/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.1856 - val_loss: 0.2604\n",
      "Epoch 215/400\n",
      "156/156 [==============================] - 0s 616us/sample - loss: 0.1861 - val_loss: 0.2588\n",
      "Epoch 216/400\n",
      "156/156 [==============================] - 0s 641us/sample - loss: 0.1851 - val_loss: 0.2583\n",
      "Epoch 217/400\n",
      "156/156 [==============================] - 0s 622us/sample - loss: 0.1840 - val_loss: 0.2638\n",
      "Epoch 218/400\n",
      "156/156 [==============================] - 0s 664us/sample - loss: 0.1835 - val_loss: 0.2633\n",
      "Epoch 219/400\n",
      "156/156 [==============================] - 0s 726us/sample - loss: 0.1830 - val_loss: 0.2622\n",
      "Epoch 220/400\n",
      "156/156 [==============================] - 0s 624us/sample - loss: 0.1827 - val_loss: 0.2562\n",
      "Epoch 221/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.1822 - val_loss: 0.2586\n",
      "Epoch 222/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.1810 - val_loss: 0.2577\n",
      "Epoch 223/400\n",
      "156/156 [==============================] - 0s 842us/sample - loss: 0.1805 - val_loss: 0.2585\n",
      "Epoch 224/400\n",
      "156/156 [==============================] - 0s 709us/sample - loss: 0.1798 - val_loss: 0.2550\n",
      "Epoch 225/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.1795 - val_loss: 0.2579\n",
      "Epoch 226/400\n",
      "156/156 [==============================] - 0s 720us/sample - loss: 0.1784 - val_loss: 0.2575\n",
      "Epoch 227/400\n",
      "156/156 [==============================] - 0s 729us/sample - loss: 0.1783 - val_loss: 0.2597\n",
      "Epoch 228/400\n",
      "156/156 [==============================] - 0s 604us/sample - loss: 0.1785 - val_loss: 0.2523\n",
      "Epoch 229/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.1777 - val_loss: 0.2513\n",
      "Epoch 230/400\n",
      "156/156 [==============================] - 0s 760us/sample - loss: 0.1772 - val_loss: 0.2616\n",
      "Epoch 231/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 626us/sample - loss: 0.1760 - val_loss: 0.2611\n",
      "Epoch 232/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.1754 - val_loss: 0.2602\n",
      "Epoch 233/400\n",
      "156/156 [==============================] - 0s 877us/sample - loss: 0.1747 - val_loss: 0.2525\n",
      "Epoch 234/400\n",
      "156/156 [==============================] - 0s 856us/sample - loss: 0.1742 - val_loss: 0.2488\n",
      "Epoch 235/400\n",
      "156/156 [==============================] - 0s 827us/sample - loss: 0.1739 - val_loss: 0.2548\n",
      "Epoch 236/400\n",
      "156/156 [==============================] - 0s 915us/sample - loss: 0.1729 - val_loss: 0.2536\n",
      "Epoch 237/400\n",
      "156/156 [==============================] - 0s 694us/sample - loss: 0.1733 - val_loss: 0.2518\n",
      "Epoch 238/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.1716 - val_loss: 0.2568\n",
      "Epoch 239/400\n",
      "156/156 [==============================] - 0s 611us/sample - loss: 0.1715 - val_loss: 0.2566\n",
      "Epoch 240/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.1709 - val_loss: 0.2561\n",
      "Epoch 241/400\n",
      "156/156 [==============================] - 0s 680us/sample - loss: 0.1707 - val_loss: 0.2566\n",
      "Epoch 242/400\n",
      "156/156 [==============================] - 0s 748us/sample - loss: 0.1702 - val_loss: 0.2527\n",
      "Epoch 243/400\n",
      "156/156 [==============================] - 0s 703us/sample - loss: 0.1696 - val_loss: 0.2549\n",
      "Epoch 244/400\n",
      "156/156 [==============================] - 0s 596us/sample - loss: 0.1697 - val_loss: 0.2507\n",
      "Epoch 245/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.1680 - val_loss: 0.2545\n",
      "Epoch 246/400\n",
      "156/156 [==============================] - 0s 648us/sample - loss: 0.1676 - val_loss: 0.2559\n",
      "Epoch 247/400\n",
      "156/156 [==============================] - 0s 591us/sample - loss: 0.1677 - val_loss: 0.2529\n",
      "Epoch 248/400\n",
      "156/156 [==============================] - 0s 594us/sample - loss: 0.1678 - val_loss: 0.2491\n",
      "Epoch 249/400\n",
      "156/156 [==============================] - 0s 597us/sample - loss: 0.1665 - val_loss: 0.2534\n",
      "Epoch 250/400\n",
      "156/156 [==============================] - 0s 864us/sample - loss: 0.1660 - val_loss: 0.2555\n",
      "Epoch 251/400\n",
      "156/156 [==============================] - 0s 857us/sample - loss: 0.1651 - val_loss: 0.2522\n",
      "Epoch 252/400\n",
      "156/156 [==============================] - 0s 832us/sample - loss: 0.1648 - val_loss: 0.2532\n",
      "Epoch 253/400\n",
      "156/156 [==============================] - 0s 817us/sample - loss: 0.1651 - val_loss: 0.2486\n",
      "Epoch 254/400\n",
      "156/156 [==============================] - 0s 824us/sample - loss: 0.1639 - val_loss: 0.2534\n",
      "Epoch 255/400\n",
      "156/156 [==============================] - 0s 854us/sample - loss: 0.1637 - val_loss: 0.2573\n",
      "Epoch 256/400\n",
      "156/156 [==============================] - 0s 640us/sample - loss: 0.1630 - val_loss: 0.2529\n",
      "Epoch 257/400\n",
      "156/156 [==============================] - 0s 633us/sample - loss: 0.1663 - val_loss: 0.2440\n",
      "Epoch 258/400\n",
      "156/156 [==============================] - 0s 617us/sample - loss: 0.1636 - val_loss: 0.2582\n",
      "Epoch 259/400\n",
      "156/156 [==============================] - 0s 616us/sample - loss: 0.1622 - val_loss: 0.2551\n",
      "Epoch 260/400\n",
      "156/156 [==============================] - 0s 907us/sample - loss: 0.1623 - val_loss: 0.2572\n",
      "Epoch 261/400\n",
      "156/156 [==============================] - 0s 879us/sample - loss: 0.1606 - val_loss: 0.2521\n",
      "Epoch 262/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1612 - val_loss: 0.2435\n",
      "Epoch 263/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1607 - val_loss: 0.2487\n",
      "Epoch 264/400\n",
      "156/156 [==============================] - 0s 865us/sample - loss: 0.1607 - val_loss: 0.2550\n",
      "Epoch 265/400\n",
      "156/156 [==============================] - 0s 705us/sample - loss: 0.1593 - val_loss: 0.2499\n",
      "Epoch 266/400\n",
      "156/156 [==============================] - 0s 663us/sample - loss: 0.1587 - val_loss: 0.2473\n",
      "Epoch 267/400\n",
      "156/156 [==============================] - 0s 688us/sample - loss: 0.1580 - val_loss: 0.2466\n",
      "Epoch 268/400\n",
      "156/156 [==============================] - 0s 693us/sample - loss: 0.1576 - val_loss: 0.2529\n",
      "Epoch 269/400\n",
      "156/156 [==============================] - 0s 692us/sample - loss: 0.1584 - val_loss: 0.2561\n",
      "Epoch 270/400\n",
      "156/156 [==============================] - 0s 594us/sample - loss: 0.1567 - val_loss: 0.2503\n",
      "Epoch 271/400\n",
      "156/156 [==============================] - 0s 635us/sample - loss: 0.1563 - val_loss: 0.2500\n",
      "Epoch 272/400\n",
      "156/156 [==============================] - 0s 641us/sample - loss: 0.1563 - val_loss: 0.2434\n",
      "Epoch 273/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.1567 - val_loss: 0.2491\n",
      "Epoch 274/400\n",
      "156/156 [==============================] - 0s 924us/sample - loss: 0.1569 - val_loss: 0.2540\n",
      "Epoch 275/400\n",
      "156/156 [==============================] - 0s 931us/sample - loss: 0.1552 - val_loss: 0.2502\n",
      "Epoch 276/400\n",
      "156/156 [==============================] - 0s 943us/sample - loss: 0.1537 - val_loss: 0.2400\n",
      "Epoch 277/400\n",
      "156/156 [==============================] - 0s 851us/sample - loss: 0.1543 - val_loss: 0.2392\n",
      "Epoch 278/400\n",
      "156/156 [==============================] - 0s 873us/sample - loss: 0.1536 - val_loss: 0.2426\n",
      "Epoch 279/400\n",
      "156/156 [==============================] - 0s 984us/sample - loss: 0.1533 - val_loss: 0.2527\n",
      "Epoch 280/400\n",
      "156/156 [==============================] - 0s 930us/sample - loss: 0.1530 - val_loss: 0.2538\n",
      "Epoch 281/400\n",
      "156/156 [==============================] - 0s 844us/sample - loss: 0.1526 - val_loss: 0.2528\n",
      "Epoch 282/400\n",
      "156/156 [==============================] - 0s 836us/sample - loss: 0.1516 - val_loss: 0.2481\n",
      "Epoch 283/400\n",
      "156/156 [==============================] - 0s 742us/sample - loss: 0.1514 - val_loss: 0.2474\n",
      "Epoch 284/400\n",
      "156/156 [==============================] - 0s 812us/sample - loss: 0.1520 - val_loss: 0.2428\n",
      "Epoch 285/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.1507 - val_loss: 0.2451\n",
      "Epoch 286/400\n",
      "156/156 [==============================] - 0s 640us/sample - loss: 0.1514 - val_loss: 0.2528\n",
      "Epoch 287/400\n",
      "156/156 [==============================] - 0s 792us/sample - loss: 0.1504 - val_loss: 0.2467\n",
      "Epoch 288/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.1494 - val_loss: 0.2426\n",
      "Epoch 289/400\n",
      "156/156 [==============================] - 0s 717us/sample - loss: 0.1493 - val_loss: 0.2437\n",
      "Epoch 290/400\n",
      "156/156 [==============================] - 0s 888us/sample - loss: 0.1483 - val_loss: 0.2458\n",
      "Epoch 291/400\n",
      "156/156 [==============================] - 0s 869us/sample - loss: 0.1480 - val_loss: 0.2469\n",
      "Epoch 292/400\n",
      "156/156 [==============================] - 0s 853us/sample - loss: 0.1477 - val_loss: 0.2520\n",
      "Epoch 293/400\n",
      "156/156 [==============================] - 0s 896us/sample - loss: 0.1478 - val_loss: 0.2485\n",
      "Epoch 294/400\n",
      "156/156 [==============================] - 0s 811us/sample - loss: 0.1477 - val_loss: 0.2450\n",
      "Epoch 295/400\n",
      "156/156 [==============================] - 0s 918us/sample - loss: 0.1475 - val_loss: 0.2515\n",
      "Epoch 296/400\n",
      "156/156 [==============================] - 0s 868us/sample - loss: 0.1468 - val_loss: 0.2434\n",
      "Epoch 297/400\n",
      "156/156 [==============================] - 0s 907us/sample - loss: 0.1466 - val_loss: 0.2482\n",
      "Epoch 298/400\n",
      "156/156 [==============================] - 0s 939us/sample - loss: 0.1454 - val_loss: 0.2457\n",
      "Epoch 299/400\n",
      "156/156 [==============================] - 0s 932us/sample - loss: 0.1454 - val_loss: 0.2442\n",
      "Epoch 300/400\n",
      "156/156 [==============================] - 0s 986us/sample - loss: 0.1450 - val_loss: 0.2466\n",
      "Epoch 301/400\n",
      "156/156 [==============================] - 0s 968us/sample - loss: 0.1442 - val_loss: 0.2429\n",
      "Epoch 302/400\n",
      "156/156 [==============================] - 0s 913us/sample - loss: 0.1443 - val_loss: 0.2388\n",
      "Epoch 303/400\n",
      "156/156 [==============================] - 0s 829us/sample - loss: 0.1437 - val_loss: 0.2432\n",
      "Epoch 304/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1454 - val_loss: 0.2528\n",
      "Epoch 305/400\n",
      "156/156 [==============================] - 0s 666us/sample - loss: 0.1434 - val_loss: 0.2481\n",
      "Epoch 306/400\n",
      "156/156 [==============================] - 0s 641us/sample - loss: 0.1421 - val_loss: 0.2407\n",
      "Epoch 307/400\n",
      "156/156 [==============================] - 0s 719us/sample - loss: 0.1434 - val_loss: 0.2386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/400\n",
      "156/156 [==============================] - 0s 633us/sample - loss: 0.1443 - val_loss: 0.2492\n",
      "Epoch 309/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.1419 - val_loss: 0.2438\n",
      "Epoch 310/400\n",
      "156/156 [==============================] - 0s 807us/sample - loss: 0.1423 - val_loss: 0.2359\n",
      "Epoch 311/400\n",
      "156/156 [==============================] - 0s 656us/sample - loss: 0.1410 - val_loss: 0.2410\n",
      "Epoch 312/400\n",
      "156/156 [==============================] - 0s 690us/sample - loss: 0.1404 - val_loss: 0.2422\n",
      "Epoch 313/400\n",
      "156/156 [==============================] - 0s 875us/sample - loss: 0.1412 - val_loss: 0.2513\n",
      "Epoch 314/400\n",
      "156/156 [==============================] - 0s 683us/sample - loss: 0.1398 - val_loss: 0.2448\n",
      "Epoch 315/400\n",
      "156/156 [==============================] - 0s 646us/sample - loss: 0.1394 - val_loss: 0.2379\n",
      "Epoch 316/400\n",
      "156/156 [==============================] - 0s 683us/sample - loss: 0.1391 - val_loss: 0.2395\n",
      "Epoch 317/400\n",
      "156/156 [==============================] - 0s 882us/sample - loss: 0.1385 - val_loss: 0.2436\n",
      "Epoch 318/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1384 - val_loss: 0.2430\n",
      "Epoch 319/400\n",
      "156/156 [==============================] - 0s 891us/sample - loss: 0.1377 - val_loss: 0.2441\n",
      "Epoch 320/400\n",
      "156/156 [==============================] - 0s 851us/sample - loss: 0.1376 - val_loss: 0.2459\n",
      "Epoch 321/400\n",
      "156/156 [==============================] - 0s 797us/sample - loss: 0.1373 - val_loss: 0.2404\n",
      "Epoch 322/400\n",
      "156/156 [==============================] - 0s 830us/sample - loss: 0.1378 - val_loss: 0.2370\n",
      "Epoch 323/400\n",
      "156/156 [==============================] - 0s 866us/sample - loss: 0.1363 - val_loss: 0.2433\n",
      "Epoch 324/400\n",
      "156/156 [==============================] - 0s 867us/sample - loss: 0.1370 - val_loss: 0.2521\n",
      "Epoch 325/400\n",
      "156/156 [==============================] - 0s 795us/sample - loss: 0.1368 - val_loss: 0.2442\n",
      "Epoch 326/400\n",
      "156/156 [==============================] - 0s 662us/sample - loss: 0.1356 - val_loss: 0.2417\n",
      "Epoch 327/400\n",
      "156/156 [==============================] - 0s 899us/sample - loss: 0.1352 - val_loss: 0.2400\n",
      "Epoch 328/400\n",
      "156/156 [==============================] - 0s 794us/sample - loss: 0.1347 - val_loss: 0.2359\n",
      "Epoch 329/400\n",
      "156/156 [==============================] - 0s 791us/sample - loss: 0.1344 - val_loss: 0.2357\n",
      "Epoch 330/400\n",
      "156/156 [==============================] - 0s 816us/sample - loss: 0.1343 - val_loss: 0.2426\n",
      "Epoch 331/400\n",
      "156/156 [==============================] - 0s 841us/sample - loss: 0.1335 - val_loss: 0.2420\n",
      "Epoch 332/400\n",
      "156/156 [==============================] - 0s 802us/sample - loss: 0.1331 - val_loss: 0.2403\n",
      "Epoch 333/400\n",
      "156/156 [==============================] - 0s 852us/sample - loss: 0.1336 - val_loss: 0.2430\n",
      "Epoch 334/400\n",
      "156/156 [==============================] - 0s 677us/sample - loss: 0.1327 - val_loss: 0.2407\n",
      "Epoch 335/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.1319 - val_loss: 0.2365\n",
      "Epoch 336/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.1322 - val_loss: 0.2324\n",
      "Epoch 337/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.1313 - val_loss: 0.2358\n",
      "Epoch 338/400\n",
      "156/156 [==============================] - 0s 634us/sample - loss: 0.1312 - val_loss: 0.2413\n",
      "Epoch 339/400\n",
      "156/156 [==============================] - 0s 722us/sample - loss: 0.1319 - val_loss: 0.2468\n",
      "Epoch 340/400\n",
      "156/156 [==============================] - 0s 734us/sample - loss: 0.1304 - val_loss: 0.2383\n",
      "Epoch 341/400\n",
      "156/156 [==============================] - 0s 603us/sample - loss: 0.1300 - val_loss: 0.2353\n",
      "Epoch 342/400\n",
      "156/156 [==============================] - 0s 989us/sample - loss: 0.1300 - val_loss: 0.2343\n",
      "Epoch 343/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.1297 - val_loss: 0.2429\n",
      "Epoch 344/400\n",
      "156/156 [==============================] - 0s 612us/sample - loss: 0.1292 - val_loss: 0.2432\n",
      "Epoch 345/400\n",
      "156/156 [==============================] - 0s 632us/sample - loss: 0.1291 - val_loss: 0.2358\n",
      "Epoch 346/400\n",
      "156/156 [==============================] - 0s 655us/sample - loss: 0.1295 - val_loss: 0.2388\n",
      "Epoch 347/400\n",
      "156/156 [==============================] - 0s 691us/sample - loss: 0.1286 - val_loss: 0.2307\n",
      "Epoch 348/400\n",
      "156/156 [==============================] - 0s 642us/sample - loss: 0.1276 - val_loss: 0.2335\n",
      "Epoch 349/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.1275 - val_loss: 0.2379\n",
      "Epoch 350/400\n",
      "156/156 [==============================] - 0s 616us/sample - loss: 0.1268 - val_loss: 0.2393\n",
      "Epoch 351/400\n",
      "156/156 [==============================] - 0s 659us/sample - loss: 0.1268 - val_loss: 0.2372\n",
      "Epoch 352/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.1269 - val_loss: 0.2327\n",
      "Epoch 353/400\n",
      "156/156 [==============================] - 0s 674us/sample - loss: 0.1260 - val_loss: 0.2370\n",
      "Epoch 354/400\n",
      "156/156 [==============================] - 0s 683us/sample - loss: 0.1260 - val_loss: 0.2409\n",
      "Epoch 355/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.1255 - val_loss: 0.2330\n",
      "Epoch 356/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.1260 - val_loss: 0.2391\n",
      "Epoch 357/400\n",
      "156/156 [==============================] - 0s 898us/sample - loss: 0.1249 - val_loss: 0.2333\n",
      "Epoch 358/400\n",
      "156/156 [==============================] - 0s 853us/sample - loss: 0.1253 - val_loss: 0.2301\n",
      "Epoch 359/400\n",
      "156/156 [==============================] - 0s 858us/sample - loss: 0.1237 - val_loss: 0.2349\n",
      "Epoch 360/400\n",
      "156/156 [==============================] - 0s 833us/sample - loss: 0.1241 - val_loss: 0.2373\n",
      "Epoch 361/400\n",
      "156/156 [==============================] - 0s 920us/sample - loss: 0.1235 - val_loss: 0.2386\n",
      "Epoch 362/400\n",
      "156/156 [==============================] - 0s 790us/sample - loss: 0.1236 - val_loss: 0.2342\n",
      "Epoch 363/400\n",
      "156/156 [==============================] - 0s 666us/sample - loss: 0.1227 - val_loss: 0.2360\n",
      "Epoch 364/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.1230 - val_loss: 0.2381\n",
      "Epoch 365/400\n",
      "156/156 [==============================] - 0s 660us/sample - loss: 0.1218 - val_loss: 0.2318\n",
      "Epoch 366/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.1225 - val_loss: 0.2318\n",
      "Epoch 367/400\n",
      "156/156 [==============================] - 0s 673us/sample - loss: 0.1216 - val_loss: 0.2276\n",
      "Epoch 368/400\n",
      "156/156 [==============================] - 0s 689us/sample - loss: 0.1216 - val_loss: 0.2298\n",
      "Epoch 369/400\n",
      "156/156 [==============================] - 0s 697us/sample - loss: 0.1207 - val_loss: 0.2305\n",
      "Epoch 370/400\n",
      "156/156 [==============================] - 0s 733us/sample - loss: 0.1208 - val_loss: 0.2291\n",
      "Epoch 371/400\n",
      "156/156 [==============================] - 0s 645us/sample - loss: 0.1203 - val_loss: 0.2321\n",
      "Epoch 372/400\n",
      "156/156 [==============================] - 0s 639us/sample - loss: 0.1199 - val_loss: 0.2313\n",
      "Epoch 373/400\n",
      "156/156 [==============================] - 0s 643us/sample - loss: 0.1197 - val_loss: 0.2337\n",
      "Epoch 374/400\n",
      "156/156 [==============================] - 0s 689us/sample - loss: 0.1201 - val_loss: 0.2382\n",
      "Epoch 375/400\n",
      "156/156 [==============================] - 0s 669us/sample - loss: 0.1192 - val_loss: 0.2350\n",
      "Epoch 376/400\n",
      "156/156 [==============================] - 0s 690us/sample - loss: 0.1190 - val_loss: 0.2209\n",
      "Epoch 377/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.1194 - val_loss: 0.2200\n",
      "Epoch 378/400\n",
      "156/156 [==============================] - 0s 665us/sample - loss: 0.1180 - val_loss: 0.2291\n",
      "Epoch 379/400\n",
      "156/156 [==============================] - 0s 668us/sample - loss: 0.1182 - val_loss: 0.2404\n",
      "Epoch 380/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.1177 - val_loss: 0.2368\n",
      "Epoch 381/400\n",
      "156/156 [==============================] - 0s 667us/sample - loss: 0.1182 - val_loss: 0.2252\n",
      "Epoch 382/400\n",
      "156/156 [==============================] - 0s 635us/sample - loss: 0.1179 - val_loss: 0.2212\n",
      "Epoch 383/400\n",
      "156/156 [==============================] - 0s 908us/sample - loss: 0.1164 - val_loss: 0.2315\n",
      "Epoch 384/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 848us/sample - loss: 0.1185 - val_loss: 0.2411\n",
      "Epoch 385/400\n",
      "156/156 [==============================] - 0s 875us/sample - loss: 0.1164 - val_loss: 0.2284\n",
      "Epoch 386/400\n",
      "156/156 [==============================] - 0s 877us/sample - loss: 0.1170 - val_loss: 0.2224\n",
      "Epoch 387/400\n",
      "156/156 [==============================] - 0s 862us/sample - loss: 0.1164 - val_loss: 0.2285\n",
      "Epoch 388/400\n",
      "156/156 [==============================] - 0s 851us/sample - loss: 0.1154 - val_loss: 0.2317\n",
      "Epoch 389/400\n",
      "156/156 [==============================] - 0s 787us/sample - loss: 0.1149 - val_loss: 0.2290\n",
      "Epoch 390/400\n",
      "156/156 [==============================] - 0s 648us/sample - loss: 0.1144 - val_loss: 0.2242\n",
      "Epoch 391/400\n",
      "156/156 [==============================] - 0s 642us/sample - loss: 0.1147 - val_loss: 0.2247\n",
      "Epoch 392/400\n",
      "156/156 [==============================] - 0s 620us/sample - loss: 0.1144 - val_loss: 0.2274\n",
      "Epoch 393/400\n",
      "156/156 [==============================] - 0s 589us/sample - loss: 0.1142 - val_loss: 0.2186\n",
      "Epoch 394/400\n",
      "156/156 [==============================] - 0s 583us/sample - loss: 0.1155 - val_loss: 0.2285\n",
      "Epoch 395/400\n",
      "156/156 [==============================] - 0s 692us/sample - loss: 0.1131 - val_loss: 0.2257\n",
      "Epoch 396/400\n",
      "156/156 [==============================] - 0s 760us/sample - loss: 0.1128 - val_loss: 0.2219\n",
      "Epoch 397/400\n",
      "156/156 [==============================] - 0s 676us/sample - loss: 0.1124 - val_loss: 0.2215\n",
      "Epoch 398/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.1124 - val_loss: 0.2258\n",
      "Epoch 399/400\n",
      "156/156 [==============================] - 0s 644us/sample - loss: 0.1123 - val_loss: 0.2210\n",
      "Epoch 400/400\n",
      "156/156 [==============================] - 0s 862us/sample - loss: 0.1131 - val_loss: 0.2180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4d5742d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=400, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4db38410>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(22, activation='relu'))\n",
    "\n",
    "model.add(Dense(11, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156 samples, validate on 39 samples\n",
      "Epoch 1/400\n",
      "156/156 [==============================] - 1s 9ms/sample - loss: 0.7107 - val_loss: 0.6923\n",
      "Epoch 2/400\n",
      "156/156 [==============================] - 0s 626us/sample - loss: 0.6869 - val_loss: 0.6764\n",
      "Epoch 3/400\n",
      "156/156 [==============================] - 0s 659us/sample - loss: 0.6669 - val_loss: 0.6643\n",
      "Epoch 4/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.6486 - val_loss: 0.6528\n",
      "Epoch 5/400\n",
      "156/156 [==============================] - 0s 655us/sample - loss: 0.6339 - val_loss: 0.6388\n",
      "Epoch 6/400\n",
      "156/156 [==============================] - 0s 699us/sample - loss: 0.6190 - val_loss: 0.6249\n",
      "Epoch 7/400\n",
      "156/156 [==============================] - 0s 782us/sample - loss: 0.6043 - val_loss: 0.6108\n",
      "Epoch 8/400\n",
      "156/156 [==============================] - 0s 684us/sample - loss: 0.5882 - val_loss: 0.5959\n",
      "Epoch 9/400\n",
      "156/156 [==============================] - 0s 616us/sample - loss: 0.5715 - val_loss: 0.5809\n",
      "Epoch 10/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.5544 - val_loss: 0.5657\n",
      "Epoch 11/400\n",
      "156/156 [==============================] - 0s 775us/sample - loss: 0.5375 - val_loss: 0.5508\n",
      "Epoch 12/400\n",
      "156/156 [==============================] - 0s 793us/sample - loss: 0.5208 - val_loss: 0.5378\n",
      "Epoch 13/400\n",
      "156/156 [==============================] - 0s 805us/sample - loss: 0.5052 - val_loss: 0.5259\n",
      "Epoch 14/400\n",
      "156/156 [==============================] - 0s 755us/sample - loss: 0.4938 - val_loss: 0.5154\n",
      "Epoch 15/400\n",
      "156/156 [==============================] - 0s 681us/sample - loss: 0.4820 - val_loss: 0.5058\n",
      "Epoch 16/400\n",
      "156/156 [==============================] - 0s 685us/sample - loss: 0.4743 - val_loss: 0.4966\n",
      "Epoch 17/400\n",
      "156/156 [==============================] - 0s 657us/sample - loss: 0.4661 - val_loss: 0.4878\n",
      "Epoch 18/400\n",
      "156/156 [==============================] - 0s 701us/sample - loss: 0.4597 - val_loss: 0.4794\n",
      "Epoch 19/400\n",
      "156/156 [==============================] - 0s 657us/sample - loss: 0.4533 - val_loss: 0.4708\n",
      "Epoch 20/400\n",
      "156/156 [==============================] - 0s 645us/sample - loss: 0.4468 - val_loss: 0.4626\n",
      "Epoch 21/400\n",
      "156/156 [==============================] - 0s 743us/sample - loss: 0.4417 - val_loss: 0.4540\n",
      "Epoch 22/400\n",
      "156/156 [==============================] - 0s 692us/sample - loss: 0.4360 - val_loss: 0.4460\n",
      "Epoch 23/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.4301 - val_loss: 0.4383\n",
      "Epoch 24/400\n",
      "156/156 [==============================] - 0s 667us/sample - loss: 0.4249 - val_loss: 0.4308\n",
      "Epoch 25/400\n",
      "156/156 [==============================] - 0s 679us/sample - loss: 0.4200 - val_loss: 0.4229\n",
      "Epoch 26/400\n",
      "156/156 [==============================] - 0s 783us/sample - loss: 0.4143 - val_loss: 0.4153\n",
      "Epoch 27/400\n",
      "156/156 [==============================] - 0s 711us/sample - loss: 0.4090 - val_loss: 0.4078\n",
      "Epoch 28/400\n",
      "156/156 [==============================] - 0s 688us/sample - loss: 0.4050 - val_loss: 0.4004\n",
      "Epoch 29/400\n",
      "156/156 [==============================] - 0s 742us/sample - loss: 0.3994 - val_loss: 0.3935\n",
      "Epoch 30/400\n",
      "156/156 [==============================] - 0s 772us/sample - loss: 0.3947 - val_loss: 0.3870\n",
      "Epoch 31/400\n",
      "156/156 [==============================] - 0s 796us/sample - loss: 0.3907 - val_loss: 0.3808\n",
      "Epoch 32/400\n",
      "156/156 [==============================] - 0s 622us/sample - loss: 0.3861 - val_loss: 0.3748\n",
      "Epoch 33/400\n",
      "156/156 [==============================] - 0s 616us/sample - loss: 0.3818 - val_loss: 0.3689\n",
      "Epoch 34/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.3782 - val_loss: 0.3633\n",
      "Epoch 35/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.3738 - val_loss: 0.3582\n",
      "Epoch 36/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.3706 - val_loss: 0.3532\n",
      "Epoch 37/400\n",
      "156/156 [==============================] - 0s 667us/sample - loss: 0.3672 - val_loss: 0.3489\n",
      "Epoch 38/400\n",
      "156/156 [==============================] - 0s 618us/sample - loss: 0.3634 - val_loss: 0.3446\n",
      "Epoch 39/400\n",
      "156/156 [==============================] - 0s 659us/sample - loss: 0.3611 - val_loss: 0.3407\n",
      "Epoch 40/400\n",
      "156/156 [==============================] - 0s 699us/sample - loss: 0.3575 - val_loss: 0.3373\n",
      "Epoch 41/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.3546 - val_loss: 0.3334\n",
      "Epoch 42/400\n",
      "156/156 [==============================] - 0s 620us/sample - loss: 0.3520 - val_loss: 0.3303\n",
      "Epoch 43/400\n",
      "156/156 [==============================] - 0s 645us/sample - loss: 0.3498 - val_loss: 0.3273\n",
      "Epoch 44/400\n",
      "156/156 [==============================] - 0s 597us/sample - loss: 0.3466 - val_loss: 0.3241\n",
      "Epoch 45/400\n",
      "156/156 [==============================] - 0s 660us/sample - loss: 0.3441 - val_loss: 0.3212\n",
      "Epoch 46/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.3419 - val_loss: 0.3189\n",
      "Epoch 47/400\n",
      "156/156 [==============================] - 0s 655us/sample - loss: 0.3393 - val_loss: 0.3168\n",
      "Epoch 48/400\n",
      "156/156 [==============================] - 0s 632us/sample - loss: 0.3373 - val_loss: 0.3145\n",
      "Epoch 49/400\n",
      "156/156 [==============================] - 0s 620us/sample - loss: 0.3349 - val_loss: 0.3127\n",
      "Epoch 50/400\n",
      "156/156 [==============================] - 0s 655us/sample - loss: 0.3334 - val_loss: 0.3111\n",
      "Epoch 51/400\n",
      "156/156 [==============================] - 0s 605us/sample - loss: 0.3311 - val_loss: 0.3087\n",
      "Epoch 52/400\n",
      "156/156 [==============================] - 0s 609us/sample - loss: 0.3293 - val_loss: 0.3068\n",
      "Epoch 53/400\n",
      "156/156 [==============================] - 0s 609us/sample - loss: 0.3273 - val_loss: 0.3052\n",
      "Epoch 54/400\n",
      "156/156 [==============================] - 0s 592us/sample - loss: 0.3256 - val_loss: 0.3037\n",
      "Epoch 55/400\n",
      "156/156 [==============================] - 0s 617us/sample - loss: 0.3243 - val_loss: 0.3024\n",
      "Epoch 56/400\n",
      "156/156 [==============================] - 0s 586us/sample - loss: 0.3221 - val_loss: 0.3014\n",
      "Epoch 57/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.3204 - val_loss: 0.3000\n",
      "Epoch 58/400\n",
      "156/156 [==============================] - 0s 651us/sample - loss: 0.3192 - val_loss: 0.2990\n",
      "Epoch 59/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.3172 - val_loss: 0.2978\n",
      "Epoch 60/400\n",
      "156/156 [==============================] - 0s 607us/sample - loss: 0.3156 - val_loss: 0.2967\n",
      "Epoch 61/400\n",
      "156/156 [==============================] - 0s 663us/sample - loss: 0.3143 - val_loss: 0.2953\n",
      "Epoch 62/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.3130 - val_loss: 0.2943\n",
      "Epoch 63/400\n",
      "156/156 [==============================] - 0s 647us/sample - loss: 0.3114 - val_loss: 0.2935\n",
      "Epoch 64/400\n",
      "156/156 [==============================] - 0s 640us/sample - loss: 0.3099 - val_loss: 0.2924\n",
      "Epoch 65/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.3087 - val_loss: 0.2920\n",
      "Epoch 66/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.3073 - val_loss: 0.2909\n",
      "Epoch 67/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.3063 - val_loss: 0.2900\n",
      "Epoch 68/400\n",
      "156/156 [==============================] - 0s 662us/sample - loss: 0.3045 - val_loss: 0.2883\n",
      "Epoch 69/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.3031 - val_loss: 0.2878\n",
      "Epoch 70/400\n",
      "156/156 [==============================] - 0s 635us/sample - loss: 0.3023 - val_loss: 0.2866\n",
      "Epoch 71/400\n",
      "156/156 [==============================] - 0s 632us/sample - loss: 0.3005 - val_loss: 0.2855\n",
      "Epoch 72/400\n",
      "156/156 [==============================] - 0s 600us/sample - loss: 0.2991 - val_loss: 0.2846\n",
      "Epoch 73/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.2982 - val_loss: 0.2837\n",
      "Epoch 74/400\n",
      "156/156 [==============================] - 0s 610us/sample - loss: 0.2978 - val_loss: 0.2832\n",
      "Epoch 75/400\n",
      "156/156 [==============================] - 0s 624us/sample - loss: 0.2955 - val_loss: 0.2820\n",
      "Epoch 76/400\n",
      "156/156 [==============================] - 0s 613us/sample - loss: 0.2947 - val_loss: 0.2810\n",
      "Epoch 77/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.2935 - val_loss: 0.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/400\n",
      "156/156 [==============================] - 0s 646us/sample - loss: 0.2925 - val_loss: 0.2787\n",
      "Epoch 79/400\n",
      "156/156 [==============================] - 0s 584us/sample - loss: 0.2912 - val_loss: 0.2778\n",
      "Epoch 80/400\n",
      "156/156 [==============================] - 0s 613us/sample - loss: 0.2897 - val_loss: 0.2772\n",
      "Epoch 81/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2883 - val_loss: 0.2758\n",
      "Epoch 82/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.2877 - val_loss: 0.2744\n",
      "Epoch 83/400\n",
      "156/156 [==============================] - 0s 641us/sample - loss: 0.2857 - val_loss: 0.2732\n",
      "Epoch 84/400\n",
      "156/156 [==============================] - 0s 609us/sample - loss: 0.2849 - val_loss: 0.2717\n",
      "Epoch 85/400\n",
      "156/156 [==============================] - 0s 592us/sample - loss: 0.2836 - val_loss: 0.2706\n",
      "Epoch 86/400\n",
      "156/156 [==============================] - 0s 603us/sample - loss: 0.2828 - val_loss: 0.2697\n",
      "Epoch 87/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.2813 - val_loss: 0.2684\n",
      "Epoch 88/400\n",
      "156/156 [==============================] - 0s 614us/sample - loss: 0.2816 - val_loss: 0.2685\n",
      "Epoch 89/400\n",
      "156/156 [==============================] - 0s 777us/sample - loss: 0.2784 - val_loss: 0.2675\n",
      "Epoch 90/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.2783 - val_loss: 0.2661\n",
      "Epoch 91/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.2768 - val_loss: 0.2652\n",
      "Epoch 92/400\n",
      "156/156 [==============================] - 0s 608us/sample - loss: 0.2754 - val_loss: 0.2644\n",
      "Epoch 93/400\n",
      "156/156 [==============================] - 0s 612us/sample - loss: 0.2760 - val_loss: 0.2646\n",
      "Epoch 94/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.2733 - val_loss: 0.2639\n",
      "Epoch 95/400\n",
      "156/156 [==============================] - 0s 601us/sample - loss: 0.2720 - val_loss: 0.2632\n",
      "Epoch 96/400\n",
      "156/156 [==============================] - 0s 709us/sample - loss: 0.2711 - val_loss: 0.2625\n",
      "Epoch 97/400\n",
      "156/156 [==============================] - 0s 743us/sample - loss: 0.2699 - val_loss: 0.2619\n",
      "Epoch 98/400\n",
      "156/156 [==============================] - 0s 624us/sample - loss: 0.2690 - val_loss: 0.2610\n",
      "Epoch 99/400\n",
      "156/156 [==============================] - 0s 633us/sample - loss: 0.2683 - val_loss: 0.2602\n",
      "Epoch 100/400\n",
      "156/156 [==============================] - 0s 791us/sample - loss: 0.2668 - val_loss: 0.2596\n",
      "Epoch 101/400\n",
      "156/156 [==============================] - 0s 684us/sample - loss: 0.2661 - val_loss: 0.2587\n",
      "Epoch 102/400\n",
      "156/156 [==============================] - 0s 589us/sample - loss: 0.2658 - val_loss: 0.2577\n",
      "Epoch 103/400\n",
      "156/156 [==============================] - 0s 779us/sample - loss: 0.2641 - val_loss: 0.2574\n",
      "Epoch 104/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.2635 - val_loss: 0.2573\n",
      "Epoch 105/400\n",
      "156/156 [==============================] - 0s 619us/sample - loss: 0.2622 - val_loss: 0.2570\n",
      "Epoch 106/400\n",
      "156/156 [==============================] - 0s 616us/sample - loss: 0.2612 - val_loss: 0.2562\n",
      "Epoch 107/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.2609 - val_loss: 0.2547\n",
      "Epoch 108/400\n",
      "156/156 [==============================] - 0s 674us/sample - loss: 0.2598 - val_loss: 0.2541\n",
      "Epoch 109/400\n",
      "156/156 [==============================] - 0s 991us/sample - loss: 0.2582 - val_loss: 0.2536\n",
      "Epoch 110/400\n",
      "156/156 [==============================] - 0s 972us/sample - loss: 0.2581 - val_loss: 0.2525\n",
      "Epoch 111/400\n",
      "156/156 [==============================] - 0s 870us/sample - loss: 0.2568 - val_loss: 0.2527\n",
      "Epoch 112/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.2554 - val_loss: 0.2519\n",
      "Epoch 113/400\n",
      "156/156 [==============================] - 0s 932us/sample - loss: 0.2545 - val_loss: 0.2509\n",
      "Epoch 114/400\n",
      "156/156 [==============================] - 0s 866us/sample - loss: 0.2542 - val_loss: 0.2510\n",
      "Epoch 115/400\n",
      "156/156 [==============================] - 0s 867us/sample - loss: 0.2532 - val_loss: 0.2498\n",
      "Epoch 116/400\n",
      "156/156 [==============================] - 0s 715us/sample - loss: 0.2521 - val_loss: 0.2484\n",
      "Epoch 117/400\n",
      "156/156 [==============================] - 0s 912us/sample - loss: 0.2511 - val_loss: 0.2481\n",
      "Epoch 118/400\n",
      "156/156 [==============================] - 0s 862us/sample - loss: 0.2504 - val_loss: 0.2480\n",
      "Epoch 119/400\n",
      "156/156 [==============================] - 0s 885us/sample - loss: 0.2493 - val_loss: 0.2458\n",
      "Epoch 120/400\n",
      "156/156 [==============================] - 0s 977us/sample - loss: 0.2486 - val_loss: 0.2453\n",
      "Epoch 121/400\n",
      "156/156 [==============================] - 0s 809us/sample - loss: 0.2472 - val_loss: 0.2451\n",
      "Epoch 122/400\n",
      "156/156 [==============================] - 0s 817us/sample - loss: 0.2466 - val_loss: 0.2449\n",
      "Epoch 123/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.2458 - val_loss: 0.2440\n",
      "Epoch 124/400\n",
      "156/156 [==============================] - 0s 850us/sample - loss: 0.2444 - val_loss: 0.2430\n",
      "Epoch 125/400\n",
      "156/156 [==============================] - 0s 779us/sample - loss: 0.2437 - val_loss: 0.2433\n",
      "Epoch 126/400\n",
      "156/156 [==============================] - 0s 835us/sample - loss: 0.2426 - val_loss: 0.2432\n",
      "Epoch 127/400\n",
      "156/156 [==============================] - 0s 902us/sample - loss: 0.2420 - val_loss: 0.2428\n",
      "Epoch 128/400\n",
      "156/156 [==============================] - 0s 769us/sample - loss: 0.2408 - val_loss: 0.2420\n",
      "Epoch 129/400\n",
      "156/156 [==============================] - 0s 743us/sample - loss: 0.2394 - val_loss: 0.2410\n",
      "Epoch 130/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.2389 - val_loss: 0.2393\n",
      "Epoch 131/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2382 - val_loss: 0.2386\n",
      "Epoch 132/400\n",
      "156/156 [==============================] - 0s 745us/sample - loss: 0.2367 - val_loss: 0.2373\n",
      "Epoch 133/400\n",
      "156/156 [==============================] - 0s 646us/sample - loss: 0.2357 - val_loss: 0.2380\n",
      "Epoch 134/400\n",
      "156/156 [==============================] - 0s 727us/sample - loss: 0.2351 - val_loss: 0.2363\n",
      "Epoch 135/400\n",
      "156/156 [==============================] - 0s 857us/sample - loss: 0.2338 - val_loss: 0.2352\n",
      "Epoch 136/400\n",
      "156/156 [==============================] - 0s 721us/sample - loss: 0.2328 - val_loss: 0.2354\n",
      "Epoch 137/400\n",
      "156/156 [==============================] - 0s 721us/sample - loss: 0.2315 - val_loss: 0.2349\n",
      "Epoch 138/400\n",
      "156/156 [==============================] - 0s 692us/sample - loss: 0.2308 - val_loss: 0.2353\n",
      "Epoch 139/400\n",
      "156/156 [==============================] - 0s 641us/sample - loss: 0.2294 - val_loss: 0.2346\n",
      "Epoch 140/400\n",
      "156/156 [==============================] - 0s 596us/sample - loss: 0.2283 - val_loss: 0.2338\n",
      "Epoch 141/400\n",
      "156/156 [==============================] - 0s 715us/sample - loss: 0.2273 - val_loss: 0.2335\n",
      "Epoch 142/400\n",
      "156/156 [==============================] - 0s 638us/sample - loss: 0.2265 - val_loss: 0.2313\n",
      "Epoch 143/400\n",
      "156/156 [==============================] - 0s 602us/sample - loss: 0.2257 - val_loss: 0.2320\n",
      "Epoch 144/400\n",
      "156/156 [==============================] - 0s 635us/sample - loss: 0.2245 - val_loss: 0.2297\n",
      "Epoch 145/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.2229 - val_loss: 0.2300\n",
      "Epoch 146/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.2224 - val_loss: 0.2288\n",
      "Epoch 147/400\n",
      "156/156 [==============================] - 0s 808us/sample - loss: 0.2229 - val_loss: 0.2308\n",
      "Epoch 148/400\n",
      "156/156 [==============================] - 0s 775us/sample - loss: 0.2202 - val_loss: 0.2280\n",
      "Epoch 149/400\n",
      "156/156 [==============================] - 0s 683us/sample - loss: 0.2187 - val_loss: 0.2267\n",
      "Epoch 150/400\n",
      "156/156 [==============================] - 0s 720us/sample - loss: 0.2177 - val_loss: 0.2252\n",
      "Epoch 151/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.2165 - val_loss: 0.2248\n",
      "Epoch 152/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.2164 - val_loss: 0.2264\n",
      "Epoch 153/400\n",
      "156/156 [==============================] - 0s 701us/sample - loss: 0.2154 - val_loss: 0.2239\n",
      "Epoch 154/400\n",
      "156/156 [==============================] - 0s 798us/sample - loss: 0.2138 - val_loss: 0.2232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/400\n",
      "156/156 [==============================] - 0s 761us/sample - loss: 0.2124 - val_loss: 0.2228\n",
      "Epoch 156/400\n",
      "156/156 [==============================] - 0s 746us/sample - loss: 0.2114 - val_loss: 0.2232\n",
      "Epoch 157/400\n",
      "156/156 [==============================] - 0s 781us/sample - loss: 0.2106 - val_loss: 0.2226\n",
      "Epoch 158/400\n",
      "156/156 [==============================] - 0s 646us/sample - loss: 0.2093 - val_loss: 0.2205\n",
      "Epoch 159/400\n",
      "156/156 [==============================] - 0s 665us/sample - loss: 0.2088 - val_loss: 0.2202\n",
      "Epoch 160/400\n",
      "156/156 [==============================] - 0s 982us/sample - loss: 0.2075 - val_loss: 0.2199\n",
      "Epoch 161/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.2066 - val_loss: 0.2195\n",
      "Epoch 162/400\n",
      "156/156 [==============================] - 0s 664us/sample - loss: 0.2052 - val_loss: 0.2194\n",
      "Epoch 163/400\n",
      "156/156 [==============================] - 0s 633us/sample - loss: 0.2044 - val_loss: 0.2170\n",
      "Epoch 164/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.2035 - val_loss: 0.2156\n",
      "Epoch 165/400\n",
      "156/156 [==============================] - 0s 794us/sample - loss: 0.2040 - val_loss: 0.2178\n",
      "Epoch 166/400\n",
      "156/156 [==============================] - 0s 681us/sample - loss: 0.2024 - val_loss: 0.2148\n",
      "Epoch 167/400\n",
      "156/156 [==============================] - 0s 868us/sample - loss: 0.2010 - val_loss: 0.2132\n",
      "Epoch 168/400\n",
      "156/156 [==============================] - 0s 916us/sample - loss: 0.2000 - val_loss: 0.2157\n",
      "Epoch 169/400\n",
      "156/156 [==============================] - 0s 923us/sample - loss: 0.1984 - val_loss: 0.2140\n",
      "Epoch 170/400\n",
      "156/156 [==============================] - 0s 855us/sample - loss: 0.1977 - val_loss: 0.2136\n",
      "Epoch 171/400\n",
      "156/156 [==============================] - 0s 845us/sample - loss: 0.1967 - val_loss: 0.2134\n",
      "Epoch 172/400\n",
      "156/156 [==============================] - 0s 679us/sample - loss: 0.1955 - val_loss: 0.2114\n",
      "Epoch 173/400\n",
      "156/156 [==============================] - 0s 951us/sample - loss: 0.1947 - val_loss: 0.2099\n",
      "Epoch 174/400\n",
      "156/156 [==============================] - 0s 867us/sample - loss: 0.1937 - val_loss: 0.2097\n",
      "Epoch 175/400\n",
      "156/156 [==============================] - 0s 799us/sample - loss: 0.1928 - val_loss: 0.2098\n",
      "Epoch 176/400\n",
      "156/156 [==============================] - 0s 898us/sample - loss: 0.1916 - val_loss: 0.2084\n",
      "Epoch 177/400\n",
      "156/156 [==============================] - 0s 779us/sample - loss: 0.1913 - val_loss: 0.2085\n",
      "Epoch 178/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.1904 - val_loss: 0.2061\n",
      "Epoch 179/400\n",
      "156/156 [==============================] - 0s 828us/sample - loss: 0.1889 - val_loss: 0.2058\n",
      "Epoch 180/400\n",
      "156/156 [==============================] - 0s 794us/sample - loss: 0.1884 - val_loss: 0.2074\n",
      "Epoch 181/400\n",
      "156/156 [==============================] - 0s 599us/sample - loss: 0.1870 - val_loss: 0.2061\n",
      "Epoch 182/400\n",
      "156/156 [==============================] - 0s 620us/sample - loss: 0.1858 - val_loss: 0.2064\n",
      "Epoch 183/400\n",
      "156/156 [==============================] - 0s 576us/sample - loss: 0.1849 - val_loss: 0.2052\n",
      "Epoch 184/400\n",
      "156/156 [==============================] - 0s 590us/sample - loss: 0.1846 - val_loss: 0.2066\n",
      "Epoch 185/400\n",
      "156/156 [==============================] - 0s 792us/sample - loss: 0.1834 - val_loss: 0.2047\n",
      "Epoch 186/400\n",
      "156/156 [==============================] - 0s 850us/sample - loss: 0.1819 - val_loss: 0.2044\n",
      "Epoch 187/400\n",
      "156/156 [==============================] - 0s 590us/sample - loss: 0.1812 - val_loss: 0.2047\n",
      "Epoch 188/400\n",
      "156/156 [==============================] - 0s 645us/sample - loss: 0.1809 - val_loss: 0.2056\n",
      "Epoch 189/400\n",
      "156/156 [==============================] - 0s 832us/sample - loss: 0.1792 - val_loss: 0.2026\n",
      "Epoch 190/400\n",
      "156/156 [==============================] - 0s 853us/sample - loss: 0.1781 - val_loss: 0.2006\n",
      "Epoch 191/400\n",
      "156/156 [==============================] - 0s 678us/sample - loss: 0.1777 - val_loss: 0.2000\n",
      "Epoch 192/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.1768 - val_loss: 0.1992\n",
      "Epoch 193/400\n",
      "156/156 [==============================] - 0s 689us/sample - loss: 0.1757 - val_loss: 0.2012\n",
      "Epoch 194/400\n",
      "156/156 [==============================] - 0s 772us/sample - loss: 0.1748 - val_loss: 0.2006\n",
      "Epoch 195/400\n",
      "156/156 [==============================] - 0s 678us/sample - loss: 0.1738 - val_loss: 0.2010\n",
      "Epoch 196/400\n",
      "156/156 [==============================] - 0s 617us/sample - loss: 0.1744 - val_loss: 0.1973\n",
      "Epoch 197/400\n",
      "156/156 [==============================] - 0s 618us/sample - loss: 0.1721 - val_loss: 0.1972\n",
      "Epoch 198/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.1710 - val_loss: 0.1970\n",
      "Epoch 199/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.1701 - val_loss: 0.1979\n",
      "Epoch 200/400\n",
      "156/156 [==============================] - 0s 630us/sample - loss: 0.1691 - val_loss: 0.1973\n",
      "Epoch 201/400\n",
      "156/156 [==============================] - 0s 698us/sample - loss: 0.1695 - val_loss: 0.1983\n",
      "Epoch 202/400\n",
      "156/156 [==============================] - 0s 608us/sample - loss: 0.1677 - val_loss: 0.1970\n",
      "Epoch 203/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.1678 - val_loss: 0.1930\n",
      "Epoch 204/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.1661 - val_loss: 0.1944\n",
      "Epoch 205/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.1648 - val_loss: 0.1955\n",
      "Epoch 206/400\n",
      "156/156 [==============================] - 0s 607us/sample - loss: 0.1640 - val_loss: 0.1952\n",
      "Epoch 207/400\n",
      "156/156 [==============================] - 0s 599us/sample - loss: 0.1642 - val_loss: 0.1914\n",
      "Epoch 208/400\n",
      "156/156 [==============================] - 0s 585us/sample - loss: 0.1627 - val_loss: 0.1939\n",
      "Epoch 209/400\n",
      "156/156 [==============================] - 0s 605us/sample - loss: 0.1615 - val_loss: 0.1934\n",
      "Epoch 210/400\n",
      "156/156 [==============================] - 0s 556us/sample - loss: 0.1613 - val_loss: 0.1907\n",
      "Epoch 211/400\n",
      "156/156 [==============================] - 0s 585us/sample - loss: 0.1601 - val_loss: 0.1900\n",
      "Epoch 212/400\n",
      "156/156 [==============================] - 0s 601us/sample - loss: 0.1600 - val_loss: 0.1917\n",
      "Epoch 213/400\n",
      "156/156 [==============================] - 0s 585us/sample - loss: 0.1583 - val_loss: 0.1903\n",
      "Epoch 214/400\n",
      "156/156 [==============================] - 0s 609us/sample - loss: 0.1579 - val_loss: 0.1909\n",
      "Epoch 215/400\n",
      "156/156 [==============================] - 0s 582us/sample - loss: 0.1568 - val_loss: 0.1866\n",
      "Epoch 216/400\n",
      "156/156 [==============================] - 0s 584us/sample - loss: 0.1560 - val_loss: 0.1849\n",
      "Epoch 217/400\n",
      "156/156 [==============================] - 0s 572us/sample - loss: 0.1556 - val_loss: 0.1873\n",
      "Epoch 218/400\n",
      "156/156 [==============================] - 0s 569us/sample - loss: 0.1550 - val_loss: 0.1896\n",
      "Epoch 219/400\n",
      "156/156 [==============================] - 0s 607us/sample - loss: 0.1540 - val_loss: 0.1849\n",
      "Epoch 220/400\n",
      "156/156 [==============================] - 0s 632us/sample - loss: 0.1530 - val_loss: 0.1859\n",
      "Epoch 221/400\n",
      "156/156 [==============================] - 0s 595us/sample - loss: 0.1522 - val_loss: 0.1834\n",
      "Epoch 222/400\n",
      "156/156 [==============================] - 0s 579us/sample - loss: 0.1518 - val_loss: 0.1853\n",
      "Epoch 223/400\n",
      "156/156 [==============================] - 0s 611us/sample - loss: 0.1507 - val_loss: 0.1822\n",
      "Epoch 224/400\n",
      "156/156 [==============================] - 0s 575us/sample - loss: 0.1499 - val_loss: 0.1816\n",
      "Epoch 225/400\n",
      "156/156 [==============================] - 0s 609us/sample - loss: 0.1486 - val_loss: 0.1824\n",
      "Epoch 226/400\n",
      "156/156 [==============================] - 0s 598us/sample - loss: 0.1478 - val_loss: 0.1839\n",
      "Epoch 227/400\n",
      "156/156 [==============================] - 0s 602us/sample - loss: 0.1482 - val_loss: 0.1816\n",
      "Epoch 228/400\n",
      "156/156 [==============================] - 0s 572us/sample - loss: 0.1467 - val_loss: 0.1838\n",
      "Epoch 229/400\n",
      "156/156 [==============================] - 0s 590us/sample - loss: 0.1459 - val_loss: 0.1823\n",
      "Epoch 230/400\n",
      "156/156 [==============================] - 0s 580us/sample - loss: 0.1450 - val_loss: 0.1813\n",
      "Epoch 231/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 615us/sample - loss: 0.1442 - val_loss: 0.1808\n",
      "Epoch 232/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.1433 - val_loss: 0.1814\n",
      "Epoch 233/400\n",
      "156/156 [==============================] - 0s 596us/sample - loss: 0.1440 - val_loss: 0.1778\n",
      "Epoch 234/400\n",
      "156/156 [==============================] - 0s 669us/sample - loss: 0.1425 - val_loss: 0.1805\n",
      "Epoch 235/400\n",
      "156/156 [==============================] - 0s 928us/sample - loss: 0.1412 - val_loss: 0.1797\n",
      "Epoch 236/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1407 - val_loss: 0.1784\n",
      "Epoch 237/400\n",
      "156/156 [==============================] - 0s 717us/sample - loss: 0.1405 - val_loss: 0.1798\n",
      "Epoch 238/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1399 - val_loss: 0.1756\n",
      "Epoch 239/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1387 - val_loss: 0.1754\n",
      "Epoch 240/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1379 - val_loss: 0.1754\n",
      "Epoch 241/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1373 - val_loss: 0.1760\n",
      "Epoch 242/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1375 - val_loss: 0.1775\n",
      "Epoch 243/400\n",
      "156/156 [==============================] - 0s 960us/sample - loss: 0.1358 - val_loss: 0.1742\n",
      "Epoch 244/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1350 - val_loss: 0.1739\n",
      "Epoch 245/400\n",
      "156/156 [==============================] - 0s 791us/sample - loss: 0.1345 - val_loss: 0.1731\n",
      "Epoch 246/400\n",
      "156/156 [==============================] - 0s 744us/sample - loss: 0.1341 - val_loss: 0.1744\n",
      "Epoch 247/400\n",
      "156/156 [==============================] - 0s 934us/sample - loss: 0.1338 - val_loss: 0.1770\n",
      "Epoch 248/400\n",
      "156/156 [==============================] - 0s 909us/sample - loss: 0.1328 - val_loss: 0.1725\n",
      "Epoch 249/400\n",
      "156/156 [==============================] - 0s 841us/sample - loss: 0.1322 - val_loss: 0.1727\n",
      "Epoch 250/400\n",
      "156/156 [==============================] - 0s 785us/sample - loss: 0.1314 - val_loss: 0.1740\n",
      "Epoch 251/400\n",
      "156/156 [==============================] - 0s 899us/sample - loss: 0.1306 - val_loss: 0.1744\n",
      "Epoch 252/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1300 - val_loss: 0.1731\n",
      "Epoch 253/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1301 - val_loss: 0.1704\n",
      "Epoch 254/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1290 - val_loss: 0.1719\n",
      "Epoch 255/400\n",
      "156/156 [==============================] - 0s 776us/sample - loss: 0.1283 - val_loss: 0.1735\n",
      "Epoch 256/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1276 - val_loss: 0.1689\n",
      "Epoch 257/400\n",
      "156/156 [==============================] - 0s 871us/sample - loss: 0.1270 - val_loss: 0.1680\n",
      "Epoch 258/400\n",
      "156/156 [==============================] - 0s 818us/sample - loss: 0.1276 - val_loss: 0.1720\n",
      "Epoch 259/400\n",
      "156/156 [==============================] - 0s 728us/sample - loss: 0.1256 - val_loss: 0.1691\n",
      "Epoch 260/400\n",
      "156/156 [==============================] - 0s 882us/sample - loss: 0.1260 - val_loss: 0.1661\n",
      "Epoch 261/400\n",
      "156/156 [==============================] - 0s 670us/sample - loss: 0.1249 - val_loss: 0.1686\n",
      "Epoch 262/400\n",
      "156/156 [==============================] - 0s 912us/sample - loss: 0.1237 - val_loss: 0.1697\n",
      "Epoch 263/400\n",
      "156/156 [==============================] - 0s 846us/sample - loss: 0.1232 - val_loss: 0.1691\n",
      "Epoch 264/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1225 - val_loss: 0.1670\n",
      "Epoch 265/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1228 - val_loss: 0.1655\n",
      "Epoch 266/400\n",
      "156/156 [==============================] - 0s 2ms/sample - loss: 0.1215 - val_loss: 0.1680\n",
      "Epoch 267/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1209 - val_loss: 0.1687\n",
      "Epoch 268/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1211 - val_loss: 0.1697\n",
      "Epoch 269/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1202 - val_loss: 0.1649\n",
      "Epoch 270/400\n",
      "156/156 [==============================] - 0s 2ms/sample - loss: 0.1197 - val_loss: 0.1642\n",
      "Epoch 271/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1196 - val_loss: 0.1619\n",
      "Epoch 272/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1181 - val_loss: 0.1647\n",
      "Epoch 273/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1175 - val_loss: 0.1676\n",
      "Epoch 274/400\n",
      "156/156 [==============================] - 0s 957us/sample - loss: 0.1167 - val_loss: 0.1658\n",
      "Epoch 275/400\n",
      "156/156 [==============================] - 0s 996us/sample - loss: 0.1160 - val_loss: 0.1648\n",
      "Epoch 276/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1154 - val_loss: 0.1635\n",
      "Epoch 277/400\n",
      "156/156 [==============================] - 0s 987us/sample - loss: 0.1152 - val_loss: 0.1637\n",
      "Epoch 278/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.1145 - val_loss: 0.1613\n",
      "Epoch 279/400\n",
      "156/156 [==============================] - 0s 783us/sample - loss: 0.1139 - val_loss: 0.1632\n",
      "Epoch 280/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1132 - val_loss: 0.1643\n",
      "Epoch 281/400\n",
      "156/156 [==============================] - 0s 1ms/sample - loss: 0.1129 - val_loss: 0.1666\n",
      "Epoch 282/400\n",
      "156/156 [==============================] - 0s 740us/sample - loss: 0.1124 - val_loss: 0.1652\n",
      "Epoch 283/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.1114 - val_loss: 0.1625\n",
      "Epoch 284/400\n",
      "156/156 [==============================] - 0s 919us/sample - loss: 0.1114 - val_loss: 0.1586\n",
      "Epoch 285/400\n",
      "156/156 [==============================] - 0s 788us/sample - loss: 0.1111 - val_loss: 0.1608\n",
      "Epoch 286/400\n",
      "156/156 [==============================] - 0s 890us/sample - loss: 0.1107 - val_loss: 0.1572\n",
      "Epoch 287/400\n",
      "156/156 [==============================] - 0s 706us/sample - loss: 0.1095 - val_loss: 0.1605\n",
      "Epoch 288/400\n",
      "156/156 [==============================] - 0s 716us/sample - loss: 0.1088 - val_loss: 0.1611\n",
      "Epoch 289/400\n",
      "156/156 [==============================] - 0s 663us/sample - loss: 0.1083 - val_loss: 0.1629\n",
      "Epoch 290/400\n",
      "156/156 [==============================] - 0s 773us/sample - loss: 0.1078 - val_loss: 0.1630\n",
      "Epoch 291/400\n",
      "156/156 [==============================] - 0s 646us/sample - loss: 0.1077 - val_loss: 0.1598\n",
      "Epoch 292/400\n",
      "156/156 [==============================] - 0s 686us/sample - loss: 0.1068 - val_loss: 0.1603\n",
      "Epoch 293/400\n",
      "156/156 [==============================] - 0s 699us/sample - loss: 0.1064 - val_loss: 0.1593\n",
      "Epoch 294/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.1069 - val_loss: 0.1559\n",
      "Epoch 295/400\n",
      "156/156 [==============================] - 0s 669us/sample - loss: 0.1053 - val_loss: 0.1597\n",
      "Epoch 296/400\n",
      "156/156 [==============================] - 0s 678us/sample - loss: 0.1046 - val_loss: 0.1623\n",
      "Epoch 297/400\n",
      "156/156 [==============================] - 0s 662us/sample - loss: 0.1047 - val_loss: 0.1616\n",
      "Epoch 298/400\n",
      "156/156 [==============================] - 0s 699us/sample - loss: 0.1036 - val_loss: 0.1594\n",
      "Epoch 299/400\n",
      "156/156 [==============================] - 0s 791us/sample - loss: 0.1032 - val_loss: 0.1562\n",
      "Epoch 300/400\n",
      "156/156 [==============================] - 0s 684us/sample - loss: 0.1030 - val_loss: 0.1562\n",
      "Epoch 301/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.1021 - val_loss: 0.1555\n",
      "Epoch 302/400\n",
      "156/156 [==============================] - 0s 679us/sample - loss: 0.1015 - val_loss: 0.1576\n",
      "Epoch 303/400\n",
      "156/156 [==============================] - 0s 711us/sample - loss: 0.1011 - val_loss: 0.1572\n",
      "Epoch 304/400\n",
      "156/156 [==============================] - 0s 688us/sample - loss: 0.1009 - val_loss: 0.1591\n",
      "Epoch 305/400\n",
      "156/156 [==============================] - 0s 687us/sample - loss: 0.1000 - val_loss: 0.1565\n",
      "Epoch 306/400\n",
      "156/156 [==============================] - 0s 645us/sample - loss: 0.1004 - val_loss: 0.1526\n",
      "Epoch 307/400\n",
      "156/156 [==============================] - 0s 665us/sample - loss: 0.0997 - val_loss: 0.1549\n",
      "Epoch 308/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 701us/sample - loss: 0.0987 - val_loss: 0.1532\n",
      "Epoch 309/400\n",
      "156/156 [==============================] - 0s 686us/sample - loss: 0.0981 - val_loss: 0.1554\n",
      "Epoch 310/400\n",
      "156/156 [==============================] - 0s 675us/sample - loss: 0.0979 - val_loss: 0.1529\n",
      "Epoch 311/400\n",
      "156/156 [==============================] - 0s 637us/sample - loss: 0.0972 - val_loss: 0.1552\n",
      "Epoch 312/400\n",
      "156/156 [==============================] - 0s 661us/sample - loss: 0.0970 - val_loss: 0.1522\n",
      "Epoch 313/400\n",
      "156/156 [==============================] - 0s 659us/sample - loss: 0.0962 - val_loss: 0.1519\n",
      "Epoch 314/400\n",
      "156/156 [==============================] - 0s 681us/sample - loss: 0.0955 - val_loss: 0.1530\n",
      "Epoch 315/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.0952 - val_loss: 0.1547\n",
      "Epoch 316/400\n",
      "156/156 [==============================] - 0s 675us/sample - loss: 0.0952 - val_loss: 0.1545\n",
      "Epoch 317/400\n",
      "156/156 [==============================] - 0s 673us/sample - loss: 0.0949 - val_loss: 0.1498\n",
      "Epoch 318/400\n",
      "156/156 [==============================] - 0s 716us/sample - loss: 0.0945 - val_loss: 0.1515\n",
      "Epoch 319/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.0932 - val_loss: 0.1500\n",
      "Epoch 320/400\n",
      "156/156 [==============================] - 0s 676us/sample - loss: 0.0932 - val_loss: 0.1524\n",
      "Epoch 321/400\n",
      "156/156 [==============================] - 0s 681us/sample - loss: 0.0929 - val_loss: 0.1492\n",
      "Epoch 322/400\n",
      "156/156 [==============================] - 0s 664us/sample - loss: 0.0928 - val_loss: 0.1533\n",
      "Epoch 323/400\n",
      "156/156 [==============================] - 0s 672us/sample - loss: 0.0915 - val_loss: 0.1525\n",
      "Epoch 324/400\n",
      "156/156 [==============================] - 0s 668us/sample - loss: 0.0913 - val_loss: 0.1471\n",
      "Epoch 325/400\n",
      "156/156 [==============================] - 0s 655us/sample - loss: 0.0906 - val_loss: 0.1469\n",
      "Epoch 326/400\n",
      "156/156 [==============================] - 0s 663us/sample - loss: 0.0901 - val_loss: 0.1495\n",
      "Epoch 327/400\n",
      "156/156 [==============================] - 0s 690us/sample - loss: 0.0894 - val_loss: 0.1510\n",
      "Epoch 328/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.0896 - val_loss: 0.1537\n",
      "Epoch 329/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.0903 - val_loss: 0.1470\n",
      "Epoch 330/400\n",
      "156/156 [==============================] - 0s 635us/sample - loss: 0.0885 - val_loss: 0.1480\n",
      "Epoch 331/400\n",
      "156/156 [==============================] - 0s 671us/sample - loss: 0.0877 - val_loss: 0.1522\n",
      "Epoch 332/400\n",
      "156/156 [==============================] - 0s 656us/sample - loss: 0.0874 - val_loss: 0.1502\n",
      "Epoch 333/400\n",
      "156/156 [==============================] - 0s 675us/sample - loss: 0.0867 - val_loss: 0.1498\n",
      "Epoch 334/400\n",
      "156/156 [==============================] - 0s 671us/sample - loss: 0.0862 - val_loss: 0.1475\n",
      "Epoch 335/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.0874 - val_loss: 0.1517\n",
      "Epoch 336/400\n",
      "156/156 [==============================] - 0s 680us/sample - loss: 0.0859 - val_loss: 0.1459\n",
      "Epoch 337/400\n",
      "156/156 [==============================] - 0s 661us/sample - loss: 0.0847 - val_loss: 0.1460\n",
      "Epoch 338/400\n",
      "156/156 [==============================] - 0s 662us/sample - loss: 0.0843 - val_loss: 0.1483\n",
      "Epoch 339/400\n",
      "156/156 [==============================] - 0s 636us/sample - loss: 0.0840 - val_loss: 0.1461\n",
      "Epoch 340/400\n",
      "156/156 [==============================] - 0s 732us/sample - loss: 0.0837 - val_loss: 0.1452\n",
      "Epoch 341/400\n",
      "156/156 [==============================] - 0s 681us/sample - loss: 0.0834 - val_loss: 0.1443\n",
      "Epoch 342/400\n",
      "156/156 [==============================] - 0s 807us/sample - loss: 0.0826 - val_loss: 0.1466\n",
      "Epoch 343/400\n",
      "156/156 [==============================] - 0s 647us/sample - loss: 0.0825 - val_loss: 0.1478\n",
      "Epoch 344/400\n",
      "156/156 [==============================] - 0s 623us/sample - loss: 0.0820 - val_loss: 0.1488\n",
      "Epoch 345/400\n",
      "156/156 [==============================] - 0s 621us/sample - loss: 0.0816 - val_loss: 0.1451\n",
      "Epoch 346/400\n",
      "156/156 [==============================] - 0s 706us/sample - loss: 0.0814 - val_loss: 0.1474\n",
      "Epoch 347/400\n",
      "156/156 [==============================] - 0s 653us/sample - loss: 0.0803 - val_loss: 0.1448\n",
      "Epoch 348/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.0802 - val_loss: 0.1421\n",
      "Epoch 349/400\n",
      "156/156 [==============================] - 0s 629us/sample - loss: 0.0801 - val_loss: 0.1424\n",
      "Epoch 350/400\n",
      "156/156 [==============================] - 0s 692us/sample - loss: 0.0800 - val_loss: 0.1478\n",
      "Epoch 351/400\n",
      "156/156 [==============================] - 0s 658us/sample - loss: 0.0791 - val_loss: 0.1467\n",
      "Epoch 352/400\n",
      "156/156 [==============================] - 0s 647us/sample - loss: 0.0785 - val_loss: 0.1421\n",
      "Epoch 353/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.0782 - val_loss: 0.1411\n",
      "Epoch 354/400\n",
      "156/156 [==============================] - 0s 605us/sample - loss: 0.0776 - val_loss: 0.1437\n",
      "Epoch 355/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.0768 - val_loss: 0.1464\n",
      "Epoch 356/400\n",
      "156/156 [==============================] - 0s 697us/sample - loss: 0.0785 - val_loss: 0.1499\n",
      "Epoch 357/400\n",
      "156/156 [==============================] - 0s 652us/sample - loss: 0.0768 - val_loss: 0.1429\n",
      "Epoch 358/400\n",
      "156/156 [==============================] - 0s 622us/sample - loss: 0.0764 - val_loss: 0.1443\n",
      "Epoch 359/400\n",
      "156/156 [==============================] - 0s 661us/sample - loss: 0.0759 - val_loss: 0.1457\n",
      "Epoch 360/400\n",
      "156/156 [==============================] - 0s 647us/sample - loss: 0.0754 - val_loss: 0.1445\n",
      "Epoch 361/400\n",
      "156/156 [==============================] - 0s 674us/sample - loss: 0.0748 - val_loss: 0.1403\n",
      "Epoch 362/400\n",
      "156/156 [==============================] - 0s 671us/sample - loss: 0.0746 - val_loss: 0.1399\n",
      "Epoch 363/400\n",
      "156/156 [==============================] - 0s 628us/sample - loss: 0.0743 - val_loss: 0.1430\n",
      "Epoch 364/400\n",
      "156/156 [==============================] - 0s 610us/sample - loss: 0.0745 - val_loss: 0.1445\n",
      "Epoch 365/400\n",
      "156/156 [==============================] - 0s 721us/sample - loss: 0.0735 - val_loss: 0.1405\n",
      "Epoch 366/400\n",
      "156/156 [==============================] - 0s 709us/sample - loss: 0.0730 - val_loss: 0.1403\n",
      "Epoch 367/400\n",
      "156/156 [==============================] - 0s 682us/sample - loss: 0.0732 - val_loss: 0.1391\n",
      "Epoch 368/400\n",
      "156/156 [==============================] - 0s 795us/sample - loss: 0.0720 - val_loss: 0.1425\n",
      "Epoch 369/400\n",
      "156/156 [==============================] - 0s 697us/sample - loss: 0.0721 - val_loss: 0.1427\n",
      "Epoch 370/400\n",
      "156/156 [==============================] - 0s 650us/sample - loss: 0.0719 - val_loss: 0.1451\n",
      "Epoch 371/400\n",
      "156/156 [==============================] - 0s 816us/sample - loss: 0.0712 - val_loss: 0.1424\n",
      "Epoch 372/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.0711 - val_loss: 0.1426\n",
      "Epoch 373/400\n",
      "156/156 [==============================] - 0s 659us/sample - loss: 0.0710 - val_loss: 0.1408\n",
      "Epoch 374/400\n",
      "156/156 [==============================] - 0s 717us/sample - loss: 0.0704 - val_loss: 0.1411\n",
      "Epoch 375/400\n",
      "156/156 [==============================] - 0s 686us/sample - loss: 0.0700 - val_loss: 0.1401\n",
      "Epoch 376/400\n",
      "156/156 [==============================] - 0s 669us/sample - loss: 0.0695 - val_loss: 0.1417\n",
      "Epoch 377/400\n",
      "156/156 [==============================] - 0s 724us/sample - loss: 0.0692 - val_loss: 0.1403\n",
      "Epoch 378/400\n",
      "156/156 [==============================] - 0s 663us/sample - loss: 0.0689 - val_loss: 0.1409\n",
      "Epoch 379/400\n",
      "156/156 [==============================] - 0s 644us/sample - loss: 0.0683 - val_loss: 0.1408\n",
      "Epoch 380/400\n",
      "156/156 [==============================] - 0s 609us/sample - loss: 0.0680 - val_loss: 0.1403\n",
      "Epoch 381/400\n",
      "156/156 [==============================] - 0s 653us/sample - loss: 0.0683 - val_loss: 0.1390\n",
      "Epoch 382/400\n",
      "156/156 [==============================] - 0s 645us/sample - loss: 0.0673 - val_loss: 0.1395\n",
      "Epoch 383/400\n",
      "156/156 [==============================] - 0s 687us/sample - loss: 0.0669 - val_loss: 0.1407\n",
      "Epoch 384/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 0s 798us/sample - loss: 0.0669 - val_loss: 0.1390\n",
      "Epoch 385/400\n",
      "156/156 [==============================] - 0s 691us/sample - loss: 0.0665 - val_loss: 0.1401\n",
      "Epoch 386/400\n",
      "156/156 [==============================] - 0s 685us/sample - loss: 0.0666 - val_loss: 0.1383\n",
      "Epoch 387/400\n",
      "156/156 [==============================] - 0s 672us/sample - loss: 0.0658 - val_loss: 0.1414\n",
      "Epoch 388/400\n",
      "156/156 [==============================] - 0s 672us/sample - loss: 0.0658 - val_loss: 0.1450\n",
      "Epoch 389/400\n",
      "156/156 [==============================] - 0s 604us/sample - loss: 0.0655 - val_loss: 0.1442\n",
      "Epoch 390/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.0648 - val_loss: 0.1405\n",
      "Epoch 391/400\n",
      "156/156 [==============================] - 0s 643us/sample - loss: 0.0647 - val_loss: 0.1366\n",
      "Epoch 392/400\n",
      "156/156 [==============================] - 0s 726us/sample - loss: 0.0649 - val_loss: 0.1337\n",
      "Epoch 393/400\n",
      "156/156 [==============================] - 0s 690us/sample - loss: 0.0639 - val_loss: 0.1375\n",
      "Epoch 394/400\n",
      "156/156 [==============================] - 0s 627us/sample - loss: 0.0641 - val_loss: 0.1407\n",
      "Epoch 395/400\n",
      "156/156 [==============================] - 0s 664us/sample - loss: 0.0635 - val_loss: 0.1386\n",
      "Epoch 396/400\n",
      "156/156 [==============================] - 0s 654us/sample - loss: 0.0628 - val_loss: 0.1359\n",
      "Epoch 397/400\n",
      "156/156 [==============================] - 0s 625us/sample - loss: 0.0629 - val_loss: 0.1312\n",
      "Epoch 398/400\n",
      "156/156 [==============================] - 0s 649us/sample - loss: 0.0631 - val_loss: 0.1361\n",
      "Epoch 399/400\n",
      "156/156 [==============================] - 0s 655us/sample - loss: 0.0619 - val_loss: 0.1344\n",
      "Epoch 400/400\n",
      "156/156 [==============================] - 0s 631us/sample - loss: 0.0619 - val_loss: 0.1333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4dd78190>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, epochs=400, validation_data = (X_test, y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a4e378410>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.84        11\n",
      "           1       0.90      1.00      0.95        28\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.95      0.86      0.90        39\n",
      "weighted avg       0.93      0.92      0.92        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  3]\n",
      " [ 0 28]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
